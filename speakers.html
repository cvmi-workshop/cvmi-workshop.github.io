  <!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Computer Vision for Microscopy Image Analysis 2025</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/speakers.css">
</head>

<body>
    <div class="headBox">
   <!--     <div class="imgBox">
            <img class="logoBox" src="img/images/Picture2.png" alt="">

        </div>  -->

        <div class="navBox">
            <ul>
                <li>
                    <a href="./new.html"><i><strong class="new">New</strong></i></a></li>
                <li>
                    <a href="index.html"><strong>Welcome</strong></a></li>
                <li>
                    <a href="organizers.html"><strong>Organizers</strong></a></li>
                <li>
                    <a href="speakers.html"><strong>Invited Speakers</strong></a></li>
		<li>
                    <a href="program.html"><strong>Program</strong></a></li>
		<li>
                    <a href="registration.html"><strong>Registration</strong></a></li>
                <li>
                    <a href="venue.html"><strong>Attend</strong></a></li>
                <li>
                    <a href="sponsor.html"><strong>Sponsors</strong></a></li>
		<li>
                    <a href="jobs.html"><strong>Jobs</strong></a></li>
		<li>
                    <a href="comittee.html"><strong>Program Committee</strong></a></li>
                <li>
                    <a href="callForPaper.html"><strong>Call for Papers</strong></a></li>
                <li>
                    <a href="dates.html"><strong>Important Dates</strong></a></li>
                <li>
                    <a href="submission.html"><strong>Submission</strong></a></li>
                <li>
                    <a href="accepted.html"><strong>Accepted Papers</strong></a></li>
		<li>
                    <a href="spotlight.html"><strong>Works-in-Progress</strong></a></li>
		<li>
                    <a href="https://motchallenge.net/data/CTMC-v1/" target="_blank"><strong>CTMC Challenge</strong></a></li>

                <li>
                    <a href="contact.html"><strong>Contact</strong></a></li>
                <li>
                    <a href="pastcvmi.html"><strong>Past CVMIs</strong></a></li>
            </ul>
        </div>
    </div>

    <div class="contentBox">
        <div class="headImgBox">
            <img class="headImg" src="img/images/Picture25.png" alt="">
        </div>

        <div class="titleBox">
            <p style="font-size: 120%;font-weight: 700;">Invited Speakers</p>
        </div>
   
        <hr style="height:1px;border:none;border-top:1px solid #555555;">
        <div class="detailBox detailBoxSpeakers">

	  <div>
          <p>  <strong>Talk Title:</strong> Information in images for drug discovery: image-based profiling </p>
             <strong>Start Time: </strong><span>9:40 AM PDT</span><br>		
		<strong>Speaker:</strong>
                <span>Inti Zlobec, Professor, University of Bern. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Inti.png" width="200" height="225">
		</center></p>
		<strong> Abstract:</strong> Cell images contain a vast amount of quantifiable information about the status of the cell: for example, whether it is diseased, whether it is responding to a drug treatment, or whether a pathway has been disrupted by a genetic mutation. We extract hundreds of features of cells from images. Just like transcriptional profiling, the similarities and differences in the patterns of extracted features reveal connections among diseases, drugs, and genes. Improving this pipeline is an active area of research, from feature extraction to batch correction to quality control to assessing similarities.

We are harvesting similarities in image-based profiles to identify, at a single-cell level, how diseases, drugs, and genes affect cells, which can uncover small molecules’ mechanism of action, discover gene functions, predict assay outcomes, discover disease-associated phenotypes, identify the functional impact of disease-associated alleles, and find novel therapeutic candidates. As part of the JUMP-Cell Painting Consortium (Joint Undertaking for Morphological Profiling-Cell Painting) we are aiming to establish experimental and computational best practices for image-based profiling (https://jump-cellpainting.broadinstitute.org/results) and produce the world’s largest public Cell Painting gene/compound image resource, with 140,000 perturbations in five replicates, to be released November 2022. With these data and new technologies like Pooled Cell Painting and variants of the assay like LipocyteProfiler and CardioProfiler, we hope to bring drug discovery-accelerating applications to practice.
		</p>	
		<strong>Speaker Bio:</strong>
                <span>Inti Zlobec holds the position of Professor (Extraordinarius) of Digital Pathology at the Institute of Pathology, University of Bern, Switzerland. She graduated with a PhD degree in Experimental Pathology, from McGill University, Montreal, Canada in 2007 before completing a post-doctoral fellowship at the Institute of Pathology, University Hospital Basel, where she conducted tissue-based research in the field of colorectal cancer using biostatistical models. After habilitating in 2010, she received a position at the Institute of Pathology, University of Bern, where she established and led the Translational Research Unit (TRU) and later the Tissue Bank Bern (TBB). Inti Zlobec became Associate Professor in 2014. Now, she leads an inter-disciplinary research group of students and researchers using artificial intelligence and machine learning as tools to study pathology images along with other data types to discover and validate novel prognostic and predictive biomarkers for colorectal cancer patients. Inti Zlobec is a member of the Executive Team of the Center for Artificial Intelligence in Medicine (CAIM) of the University of Bern, Co-Founder and President of the Swiss Consortium for Digital Pathology (SDiPath) and Chair of the European Society of Pathology (ESP) Working Group IT.
                </span>
            </div> 

       <hr style="height:1px;border:none;border-top:1px solid #555555;" />   
       <br>
	    <div>

<!--		<p>  <strong>Talk Title:</strong> Learning and using self-supervised phenotypic features in small molecule discovery </p>	
	 		<strong>Start Time: </strong><span>11:00 AM PDT</span><br>	-->
                <strong>Speaker:</strong>
                <span>Hoifung Poon, Ph.D., General Manager, Microsoft. </span><strong></strong> <br>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Hoifung.jpg" width="200" height="200">
		</center></p>
<!--		<strong> Abstract:</strong> Small molecule phenotypic screens test the effects of hundreds of thousands of compounds using miniaturized assays and automated image acquisition. These screens generate vast datasets that can be used to understand compounds’ mode of action and toxicity, characterize disease phenotypes, uncover new biology, and more. Image featurization is a prerequisite for the utilization of the data and self-supervised learning (SSL) is particularly suitable for this task given the scarcity of phenotypic annotations or biological labels. In this talk, I will show how we use SSL to extract image representations in small molecule discovery at Bayer AG. Our models provide powerful representations of plant phenotypes in herbicide screens as well as cellular phenotypes in Cell Painting data which outperform the commonly used software Cell Profiler. I will introduce examples of how image features can be leveraged in multiple applications, including phenotype clustering, mode of action identification, prediction of mitochondrial toxicity, and de novo molecular design with generative models among others.
            </p>  	-->
		<strong>Speaker Bio:</strong>
                <span>Dr. Poon is a General Manager at Microsoft Health Futures where he leads biomedical AI research and incubation, with the overarching goal of structuring medical data to accelerate discovery and improve delivery for precision health. His team and collaborators are among the first to explore large language models (LLMs) in health applications, from foundational research to incubations at large health systems and life science companies, and ultimately to commercialization. Dr. Poon received his B.S. with Distinction in Computer Science from Sun Yat-Sen University in Guangzhou, China, and his PhD in Computer Science and Engineering from the University of Washington in Seattle, specializing in machine learning and natural language processing (NLP). He joined Microsoft Research in 2011.
        <br>
		</span>  
	      </div>
	<br>
              <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	<br>      
	      <div>

<!--		<p>  <strong>Talk Title:</strong> Building Large-Scale Foundation Models for Digital Pathology with Millions of Whole Slides and Multi-Modal Generative AI: from Virchow to PRISM </p>
                 <strong>Start Time: </strong><span>13:00 PDT</span><br>	-->
		<strong>Speaker:</strong>
                <span>Drew Linsley, Assistant Professor, Brown University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Drew.jpeg" width="200" height="200">
		</center></p>
<!--		<strong> Abstract:</strong>The application of artificial intelligence (AI) in precision medicine and decision support systems, particularly through the analysis of pathology images, holds immense potential to transform cancer diagnosis and treatment. However, implementing AI in computational pathology presents several challenges, including data heterogeneity, the need for large annotated datasets, huge compute costs, and the alignment between image tiles and whole slide information across multiple magnifications. To address these challenges, we propose a dual approach: (1) developing a family of large foundation models trained on millions of whole-slide images using self-supervised learning techniques to capture essential features and patterns across diverse pathology images; (2) pretraining an aggregator model that leverages vision and language through multimodal generative AI learning to incorporate clinical information typically reported in medical settings, thus enhancing the slide-level foundation model with richer contextual understanding. Our combined approach, developed through a collaboration between Paige and Microsoft, not only achieves state-of-the-art performance across various benchmarks but also demonstrates the generative AI’s potential to unlock new possibilities for next-generation computational pathology, promising more diverse applications and reduced development costs for better cancer diagnosis and treatment.</p>		-->
		<strong>Speaker Bio:</strong>
                <span>Dr. Linsley is an Assistant Professor (Research) in Computational Neuroscience and AI at Brown University. He previously did a postdoc with Thomas Serre, also at Brown. Before that, he received his PhD at Boston College with Sean MacEvoy, and BA at Hamilton College working with Jonathan Vaughan. He studies biological and artificial vision. He is Co-Founder and CEO at Operant Biopharma whose robotic microscope, powered by artificial intelligence, designs drugs by watching and controlling diseases over time.</span>
            </div>
	<br>
       	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
        <br>  
	    <div>

    <!--		<p>  	<strong>Talk Title:</strong> Protein Data Bank: From Two Epidemics to the Global Pandemic to mRNA Vaccines and Paxlovid</p>
            	<strong>Start Time: </strong><span>9:20 AM PDT</span><br>	
                <p><strong>Speaker:</strong> 	
                <span>Stephen K. Burley, Uniersity Professor & Henry Rutgers Chair, Rutgers University </span><strong></strong> </p>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Burley.jpg" width="170" height="210">
		</center></p>
     	  	<strong> Abstract:</strong> Structural biologists around the world and the Protein Data Bank (PDB) played decisive roles in combating the COVID-19 pandemic. This talk will explain how global three-dimensional (3D) biostructure data was turned into global knowledge, allowing scientists and engineers around the world to understand the inner workings of coronaviruses and develop effective countermeasures against SARS-CoV-2. 

State-of-the-art mRNA vaccines, initially designed with guidance from single-particle cryo-electron microscopy structures of the SARS-CoV and MERS-CoV Spike Proteins, benefited more than five billion individuals around the world by preventing viral infections entirely or significantly reducing morbidity and mortality. Structure-guided drug discovery efforts at Pfizer, first initiated in the 2000s in response to the SARS-CoV epidemic and reactivated in 2020 early in the global pandemic, yielded nirmatrelvir -- a potent, orally-bioavailable, covalently-acting, peptidomimetic inhibitor of the SARS-CoV-2 Main Protease. This targeted antiviral drug received Emergency Use Authorization from the United States Food and Drug Administration in December 2021, less than two years following public release of the viral genome sequence. It is used clinically for the treatment of acute SARS-CoV-2 infections in a fixed dose combination with ritonavir and sold under the brand name Paxlovid. 

Bolstered by open access to research data generated with public and private monies, particularly 3D structures of coronavirus proteins archived in the PDB, basic and applied researchers made a difference when the world desperately needed them to succeed. To underscore the importance of these contributions, I quote Dr. Anthony Fauci, former head of the National Institute of Allergy and Infectious Disease, “Show me a person who’s vaccinated, got infected, took Paxlovid and died. I can’t find anybody.”  
              	</p>	
                <strong>Speaker Bio:</strong>
                <span>Stephen Kevin Burley is an expert in data science and bioinformatics, structural biology, and structure-guided drug discovery for oncology. He is the Director of the RCSB Protein Data Bank (RCSB.org). Within Rutgers, The State University of New Jersey he serves as University Professor and Henry Rutgers Chair, Founding Director of the Institute for Quantitative Biomedicine, and Cancer Pharmacology Research Program Co-Leader within the Rutgers Cancer Institute of New Jersey. Burley’s  previous roles were Distinguished Lilly Research Scholar, Eli Lilly and Co.; Chief Scientific Officer and Senior Vice President for Research, SGX Pharmaceuticals, Inc.; Richard M. and Isabel P. Furlaud Professor, The Rockefeller University; and Investigator, Howard Hughes Medical Institute. His degrees include M.D. - Harvard Medical School; D.Phil. - Oxford University; and B.Sc. (physics) and Doctor of Science (Honoris causa) - Western University. Burley has published extensively in data science and bioinformatics, artificial intelligence/machine learning, structural biology, and clinical oncology.</span>
            </div>
	<br>
            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
        <br>
		<p>  <strong>Talk Title:</strong> High-throughput mapping of 3D reconstructed neurons at whole-brain scale using petavoxel-computing </p>  
                <strong>Start Time: </strong><span>16:10 PDT</span><br>	
		<strong>Speaker:</strong>
                <span>Hanchuang Peng, Ph.D, Allen Institute for Brain Science. </span> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/hanchuan.png" width="200" height="200">
		</center></p>
		<p>
        	<strong> Abstract:</strong> In this talk I will discuss our work of a large-scale study of whole-brain neuron morphometry, analyzing 3.7 peta-voxels of mouse brain images at the single-cell resolution, producing one of the largest multi-morphometry databases of mammalian brains to date. We annotated 3D locations of cell bodies of over 182,000 neurons, modeled more than 15,000 dendritic microenvironments, characterized the full morphology of over 1,800 neurons along with their axonal motifs, and detected over 2.6 million axonal varicosities that indicate potential synaptic sites. Our analysis covers six levels of information related to neuronal populations, dendritic microenvironments, single-cell full morphology, sub-neuronal dendritic and axonal arborization, axonal varicosities , and sub-neuronal structural motifs, along with a quantification of the diversity and stereotypy of patterns at each level. Overall, our study provides an integrative description of key anatomical structures of neurons and their types, covering a wide range of scales and features, and contributes a large-scale resource to understanding neuronal diversity in the mammalian brain. With this dataset, we start to formulate a possible whole brain scale connectome at the single neuron resolution for mouse brains.
            	</p>
		<strong>Speaker Bio:</strong>
                <span>Hanchuan Peng joined the Allen Institute in 2012 to build a computational neuroanatomy and smart imaging group for the Institute’s new initiatives in neural coding and cell types. His current research focuses on bioimage analysis, large-scale informatics, machine learning, as well as computational biology. Before joining the Allen Institute, Peng was the head of a computational bioimage analysis lab at Howard Hughes Medical Institute, Janelia Farm Research Campus. His recent work includes developing novel algorithms for 3-D+ image analysis and data mining, building single-neuron whole-brain level 3-D digital atlases for model animals, and Vaa3D, which is a high-performance visualization-assisted analysis system for large 3-D+ biological and biomedical-image datasets. He is also the inventor of the widely cited minimum-redundant maximum-relevance (mRMR) feature selection algorithm in machine learning. Peng received his Ph.D. in biomedical engineering from Southeast University, China. He held postdoctoral positions at the Lawrence Berkeley National Laboratory at the University of California, Berkeley (computational biology, bioinformatics, and high-performance data mining with a particular focus on gene expression analysis) and at Johns Hopkins University Medical School (human brain imaging and analysis). He won several awards, including a Cozzarelli Prize (2013) for his collaborative research on dragonfly neurons, which “recognizes outstanding contributions to the scientific disciplines represented by the National Academy of Sciences (USA)”.</span>
            </div>
	<br>
            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
	<br>
      	    <p>  <strong>Talk Title:</strong> Microscopy, foundation models, and the scaling hypothesis: a phenomenal step forward for image-based profiling</p>
		<strong>Start Time: </strong><span>8:40 AM PDT</span><br>	
        	<strong>Speaker:</strong>
		<span>Berton Earnshaw, Ph.D., Machine Learning Fellow, Recursion.</span></p>
        	<p><center>
		<img class="img-responsive" alt="" src="./img/images/Berton.jpg"  width="210" height="210">
		</center></p>
            	<p>
    		<strong> Abstract:</strong>The use of morphological profiles of cellular microscopy images is by now a widespread method of investigating the functional effects of perturbations and treatments on cellular models of disease, yet the insights gained from such analyses are only as good as the features extracted from these unstructured data. In this talk, I will describe how Recursion leveraged its phenomic datasets, computational resources, and a self-supervised learning objective to build Phenom-1, a foundation model of cellular morphology whose performance on downstream tasks like recall of known biological relationships appears to scale linearly in the logarithm of the total computational cost used to train it, a phenomenon known as the scaling hypothesis. A smaller version of this foundation model, called Phenom-Beta, was recently released under a non-commercial license on NVIDIA’s BioNemo platform. I will also briefly describe the role that foundation models like Phenom-1 play in a vision of the future of drug discovery, where AI agents generate and test hypotheses inferred from such models, and give a demo of LOWE, a first step towards this vision in which the cognitive capabilities of LLMs are leveraged to reason about and execute typical tasks involved in drug discovery: retrieval and analysis of data, design and execution of experiments, generation of compounds and prediction of their properties, etc.
          	</p>		
          	<strong>Speaker Bio: </strong>
		<span>Berton Earnshaw is a Founding Fellow at Recursion, a leading clinical-stage TechBio company, and Scientific Director at Valence Labs, an AI research lab within Recursion whose mission is to industrialize scientific discovery to radically improve lives. Berton earned a PhD in mathematics from the University of Utah in its mathematical biology group, and was a postdoc at both the University of Utah and Michigan State University. Berton has worked in many scientific and leadership roles in industry, including CTO of Perfect Pitch (now Boomsourcing), Director of Data Science and Operations at Red Brain Labs (acquired by Savvysherpa), and Principal and Senior Scientist at Savvysherpa (acquired by UnitedHealth Group). While at Recursion, Berton has led the development and deployment of many of the machine learning capabilities employed in its drug discovery workflows, and currently directs multiple research programs across Recursion and Valence Labs.</span>
	    </div>
	<br>
 	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
	<br>
          <p>  <strong>Talk Title:</strong> Predicting Patient Treatment Outcomes using (Diffusion) Generative Models </p>	
		<strong>Start Time: </strong><span>14:20 PDT</span><br>		
		<strong>Speaker:</strong>
                <span>Charlotte Bunne, Assistant Professor, EPFL. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Charlotte.jpg" width="200" height="200">
		</center></p>
		<strong> Abstract:</strong>As the smallest functioning living units, cells are key to understanding health and disease. To predict a patient’s responses to molecular drugs and design efficient treatments, it is vital to recover the underlying dynamics cells take upon administering a drug. Biologists have long sought to simulate the state and functioning of a cell in order to understand and control its core processes. In this talk, I will discuss how to use and design artificial intelligence tools combined with large biomedical datasets to infer such cellular behavior. I will cover our work on (diffusion and flow matching) generative models that robustly predict treatment responses of biopsied cells from metastatic melanoma patients. As integral part of an observational clinical cohort study, they are able to reveal otherwise hidden patterns of signaling pathway modulation associated with driver mutations and metastasis sites upon cancer treatments. Lastly, I will provide a perspective on how to develop biological foundation models and realize the vision of a virtual cell powered by artificial intelligence that will shape the future of treatment design and personalized therapies.</p>
		
		<strong>Speaker Bio:</strong>
                <span>Charlotte Bunne is an assistant professor at EPFL in the Computer Science and Life-Sciences Department. Before, she was a PostDoc at Genentech and Stanford and Before and completed a PhD in Computer Science at ETH Zurich working with Andreas Krause and Marco Cuturi. During her graduate studies, she was a visiting researcher at the Broad Institute of MIT and Harvard hosted by Anne Carpenter and Shantanu Singh and worked with Stefanie Jegelka at MIT. Her research aims to advance personalized medicine by utilizing machine learning and large-scale biomedical data. Charlotte has been a Fellow of the German National Academic Foundation and is a recipient of the ETH Medal.
                </span>
            </div>

   	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>

           <p>  <strong>Talk Title:</strong> Point-and-click: using microscopy images to guide spatial next generation sequencing measurements </p>
			<strong>Start Time: </strong><span>4:00 PM PDT</span><br>		
		<strong>Speaker:</strong>
                <span>Jocelyn Kishi, PhD, CEO & Co-Founder, Stealth TechBio Startup. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Josie.jpg" width="210" height="210">
		</center></p>
		<strong> Abstract:</strong> By using microscopy images of cells to guide multiplexed spatial indexing of sequencing reads, Light-Seq allows combined imaging and spatially resolved next generation sequencing (NGS) measurements to be captured from fixed biological samples. This is achieved through the combination of spatially targeted, rapid photocrosslinking of DNA barcodes onto complementary DNAs in situ with a one-step DNA stitching reaction to create pooled, spatially indexed sequencing libraries. Selection of cells can be done manually by pointing and clicking on the regions of interest (ROIs) to be sequenced, or automatically through the use of computer vision for cell type identification and segmentation. This foundational capability opens up a broad range of applications for multi-omic analysis unifying microscopy and NGS measurements from intact biological samples.</p>
		
		<strong>Speaker Bio:</strong>
                <span>Dr. Kishi’s research focuses on developing new methods for reading and writing DNA sequences, DNA computing and molecular robotics, and DNA-based imaging assays. My background in software engineering has allowed me to work on projects at the intersection of Computer Science and DNA Nanotechnology.
                </span>
            </div>

    	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>

           <p>  <strong>Talk Title:</strong> Enhancing SAM's Biomedical Image Analysis through Prompt-based Learning </p>
			<strong>Start Time: </strong><span>5:00 PM PDT</span><br>		
		<strong>Speaker:</strong>
                <span>Dong Xu, Curators’ Distinguished Professor, Uuniversity of Missouri, Columbia. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Dong.jpg" width="160" height="210">
		</center></p>
		<strong> Abstract:</strong> The Segment Anything Model (SAM), a foundational model trained on an extensive collection of images, presents many opportunities for diverse applications. For instance, we employed SAM in our biological pathway curation pipeline that synergizes image understanding and text mining techniques for deciphering gene relationships. SAM has proven highly efficient in recognizing pathway entities and their interconnections. However, SAM does not work well when applied to low-contrastive images directly. To counter this, we investigated prompt-based learning with SAM, specifically for identifying proteins from cryo-Electron Microscopy (cryo-EM) images. We trained a U-Net-based filter to adapt these grayscale cryo-EM images into RGB images suitable for SAM's input. We also trained continuous prompts and achieved state-of-the-art (SOTA) performance, even with a limited quantity of labeled data. The outcomes of our studies underscore the potential utilities of prompt-based learning on SAM for efficient biomedical image analyses.</p>
		
		<strong>Speaker Bio:</strong>
                <span>Dong Xu is Curators’ Distinguished Professor in the Department of Electrical Engineering and Computer Science, with appointments in the Christopher S. Bond Life Sciences Center and the Informatics Institute at the University of Missouri-Columbia. He obtained his Ph.D. from the University of Illinois, Urbana-Champaign in 1995 and did two years of postdoctoral work at the US National Cancer Institute. He was a Staff Scientist at Oak Ridge National Laboratory until 2003 before joining the University of Missouri, where he served as Department Chair of Computer Science during 2007-2016 and Director of Information Technology Program during 2017-2020. Over the past 30 years, he has conducted research in many areas of computational biology and bioinformatics, including single-cell data analysis, protein structure prediction and modeling, protein post-translational modifications, protein localization prediction, computational systems biology, biological information systems, and bioinformatics applications in human, microbes, and plants. His research since 2012 has focused on the interface between bioinformatics and deep learning. He has published more than 400 papers with more than 21,000 citations and an H-index of 73 according to Google Scholar. He was elected to the rank of American Association for the Advancement of Science (AAAS) Fellow in 2015 and American Institute for Medical and Biological Engineering (AIMBE) Fellow in 2020.
                </span>
            </div>   


        </div> -->
<br>

    </div> 
</body>

</html>