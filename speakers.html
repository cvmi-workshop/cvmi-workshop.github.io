<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Computer Vision for Microscopy Image Analysis 2021</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/speakers.css">
</head>

<body>
    <div class="headBox">
   <!--     <div class="imgBox">
            <img class="logoBox" src="img/images/Picture2.png" alt="">

        </div>  -->

        <div class="navBox">
            <ul>
                <li>
                    <a href="./new.html"><i><strong class="new">New</strong></i></a></li>
                <li>
                    <a href="index.html"><strong>Welcome</strong></a></li>
                <li>
                    <a href="organizers.html"><strong>Organizers</strong></a></li>
                <li>
                    <a href="speakers.html"><strong>Invited Speakers</strong></a></li>
		<li>
                    <a href="program.html"><strong>Program</strong></a></li>
		<li>
                    <a href="registration.html"><strong>Registration</strong></a></li>
                <li>
                    <a href="venue.html"><strong>Attend</strong></a></li>
                <li>
                    <a href="sponsor.html"><strong>Sponsors</strong></a></li>
		<li>
                    <a href="jobs.html"><strong>Jobs</strong></a></li>
		<li>
                    <a href="comittee.html"><strong>Program Committee</strong></a></li>
                <li>
                    <a href="callForPaper.html"><strong>Call for Papers</strong></a></li>
                <li>
                    <a href="dates.html"><strong>Important Dates</strong></a></li>
                <li>
                    <a href="submission.html"><strong>Submission</strong></a></li>
                <li>
                    <a href="accepted.html"><strong>Accepted Papers</strong></a></li>
		<li>
                    <a href="spotlight.html"><strong>Works-in-Progress</strong></a></li>
		<li>
                    <a href="https://motchallenge.net/data/CTMC-v1/" target="_blank"><strong>MOT Challenge</strong></a></li>

                <li>
                    <a href="contact.html"><strong>Contact</strong></a></li>
                <li>
                    <a href="pastcvmi.html"><strong>Past CVMIs</strong></a></li>
            </ul>
        </div>
    </div>

    <div class="contentBox">
        <div class="headImgBox">
            <img class="headImg" src="img/images/Picture11.png" alt="">
        </div>

        <div class="titleBox">
            <p style="font-size: 120%;font-weight: 700;">Invited Speakers</p>
        </div>
        <hr style="height:1px;border:none;border-top:1px solid #555555;">
        <div class="detailBox detailBoxSpeakers">

	    <div>
                <p>  <strong>Talk Title:</strong>  Molecular Simulation Meets Cryo Electron Tomography </p>
                <strong>Start Time: </strong><span>12:40 PM EDT</span><br>
		<strong>Speaker:</strong>
                <span>Gerhard Hummer, Ph.D., Max Planck Institute of Biophysics. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Gerhard.jpg" width="240" height="300">
		</center></p>
		<strong> Abstract:</strong> Cryo electron tomography and molecular dynamics simulations perfectly complement each other. Electron tomograms provide us with a remarkably detailed, three-dimensional view of the molecular architecture of cells and viruses in situ, that is in the natural context; however, this view is essentially static and atomic resolution remains largely out of reach, in particular for dynamic biomolecular machineries. By contrast, molecular dynamics simulations naturally give us an atomistic view that includes dynamics, albeit in an idealized context. The synergistic potential of tomography and simulation can now be realized thanks to an increase in the resolution achievable by cryo electron tomography, a rapid growth in raw computational power, significant improvements in the quality of the potential energy functions entering classical molecular dynamics simulations, and the availability of simulation codes that can handle the complex molecular systems encountered in situ. With applications to the SARS-CoV-2 viral envelope and to cell-cell junctions, I will demonstrate how molecular simulations can be used to add detail and dynamics to electron tomographic.
		</p>
		<strong>Speaker Bio:</strong>
                <span>Gerhard Hummer studied physics at the University of Vienna, Austria. He received his PhD in 1992 for work at the University of Vienna, Austria, and the Max-Planck-Institute for Biophysical Chemistry, Göttingen, Germany. He joined the Los Alamos National Laboratory (NM, USA), first as a postdoctoral fellow (1993-1996) and then as a group leader (1996-1999). In 1999, he moved to the National Institutes of Health (MD, USA), where he became Chief of the Theoretical Biophysics Section, and Deputy Chief of the Laboratory of Chemical Physics, NIDDK. In 2013 he was appointed as scientific member and director at the Max Planck Institute of Biophysics in Frankfurt, Germany, where he heads the Department of Theoretical Biophysics. Since 2016, he is also Professor of Biophysics at the Goethe University in Frankfurt.
		Gerhard Hummer uses molecular simulations, integrative modeling, and theory to study the structure, dynamics, and function of biological systems at the molecular level. His current research focuses on membrane dynamics and remodeling processes in cellular homeostasis, autophagy, and viral infection. Gerhard Hummer is a Fellow of the American Physical Society (2005), a Senior Fellow of the Frankfurt Institute for Advanced Studies (2015), and a recipient of the Raymond and Beverly Sackler International Prize in Biophysics (2010) and the Nancy Nossal Scientific Mentorship Award at the NIH (2010).
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    
	    <div>
		<p>  <strong>Talk Title:</strong> AI – New Horizons for Histopathology</p>
                <strong>Start Time: </strong><span>13:20 PM EDT</span><br>
		<strong>Speaker:</strong>
                <span>Jens Rittscher, Ph.D., University of Oxford. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Jens.jpg" width="290" height="300">
		</center></p>
<strong> Abstract:</strong> Machine learning and image analysis allows to interrogate morphological patterns with a precision and accuracy that exceeds human performance. The talk will highlight recent results that demonstrate the possibility of identifying morphological correlates of molecular subtypes in colorectal cancer using histology alone. Not only will this technology open up new opportunities for cellular pathology, it will also provide new ways for introducing certain molecular tests into the clinical workflow. Combined with new tissue imaging technologies that can visualise multiple different proteins in the same tissue section we can now interrogate tissues with a depth and resolution that has not been possible before.  In addition, I outline efforts for improving the pathology workflows using AI.</p>
		<strong>Speaker Bio:</strong>
                <span>Jens Rittscher is Professor of Engineering Science at the University of Oxford with his appointment held jointly between the Institute of Biomedical Engineering and the Nuffield Department of Medicine. He is a group leader at the Big Data Institute and affiliated to the Ludwig Institute of Cancer Research and the Wellcome Centre as an adjunct member. Previously, he was a senior research scientist and manager at GE Global Research (Niskyauna, NY, USA). His research interests lie in enabling biomedical imaging through the development of new algorithms and novel computational platforms, with a current focus to improve mechanistic understanding of cancer and patient care through quantitative analysis of image data. He is a co-director of the Oxford EPSRC Centre for Doctoral Training in Health Data Science.</span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>
                <p>  <strong>Talk Title:</strong>  Computer Vision Opportunities for Analyzing the Spatial Topography of Gene Expression in the Human Brain </p>
		<strong>Start Time: </strong><span>14:50 PM EDT</span><br>
		<strong>Speaker:</strong>
                <span>Kristen Maynard, Ph.D., Lieber Institute. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Kristen.jpg" width="220" height="300">
		</center></p>
		<strong> Abstract:</strong> The spatial organization of the brain is fundamentally related to its function. Understanding complex brain disorders will require identifying cell types that make up the brain and ultimately linking functional correlates of individual cell classes with spatial topography. Emerging approaches like spatial transcriptomics (ST) can quantify RNA transcripts within tissue architecture (defined by histological images), thereby retaining both anatomical and transcriptome-scale molecular information. To further our understanding of gene expression within the context of the spatial organization of the human cortex, we used the 10x Genomics Visium platform, a novel barcoding-based transcriptome-wide ST technology that maps RNA-sequencing reads to specific positions on a histological image, to generate spatial maps of gene expression in the six-layered dorsolateral prefrontal cortex (DLPFC) of the adult human brain.: We show that Visium and its combined proteomics platform (Visium-IF) can identify gene expression with high spatial resolution within the architecture of the human cortex. We discuss computer vision opportunities for further integrating Visium gene expression and histology/fluorescence microscopy data for spatial and pathological registration of gene expression in the normal brain as well as the brains of individuals with complex brain disorders.
           	 </p>
		
		<strong>Speaker Bio:</strong>
                <span>Kristen Maynard, Ph.D. is a Research Scientist in the Molecular Neuroanatomy Division at the Lieber Institute for Brain Development. She earned her Bachelor’s degree in Neuroscience at Bowdoin College and completed her Doctoral degree in Neuroscience at Yale University where she studied mechanisms governing cortical neuron development.  Dr. Maynard received specialized training in translational research through the Yale Medical Research Scholars Program and joined the newly established Lieber Institute for a postdoctoral fellowship in biological psychiatry with Dr. Keri Martinowich in 2012. Using cell type-specific molecular profiling techniques in combination with circuit biology and systems neuroscience in mice, she identified novel links between gene expression, plasticity, and behavior in the context of chronic stress, fear regulation, aggression, and social behavior. She was recruited as a Research Scientist to advance novel methodologies and tools for studying gene expression with single cell and spatial resolution in postmortem human brain. In collaboration with her colleagues, Dr. Maynard conducted the first transcriptome-scale spatial gene expression studies in human cortex using Visium spatial transcriptomics technology. Her cross-species research program integrates circuit-specific studies in mice with cell type-specific molecular studies in postmortem human brain to identify novel mechanisms underlying psychiatric disease and addiction for the development of therapeutic targets.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
 
            <div>
		<p>  <strong>Talk Title:</strong> Geometry of Life: Computational Organismal and Tissue Phenomics from X-ray Histotomography, Multiscale Multi-omics, and AI</p>
		<strong>Start Time: </strong><span>15:30 PM EDT</span><br>
                <strong>Speaker:</strong>
                <span>Keith C. Cheng, M.D., Ph.D., Pennsylvania State University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Keith.jpg" width="285" height="300">
		</center></p>
		<strong> Abstract:</strong> We have taken a systems approach to filling a profound gap in science: the spatially-resolved integration of increasingly data-intensive -omics tools across molecular, cellular, and organismal length scales. This approach has four anchors: 1) The cell is the 3D unit of life. 2) Cell identity and their normal and disease states are recognizable through sub-micron features discernable within cm fields of view. 3) a new form of 3D tissue imaging based on microCT, x-ray histotomography, has been developed at Penn State that, like histology, allows us to “see” every cell type and tissue without anisotropic distortion, allowing the computational characterization of shape and volume of cells, tissues, and organs. 4) Machine learning and AI applied to x-ray histotomography will allow feature measurement, computer modeling of cells and tissues, and computational phenotyping. In short, it is becoming possible to define the “Geometry of Life” digitally to the cellular level. Based on these anchors, large-field, tissue and organismal imaging will be done in 3D with cellular (submicron voxel) resolution across all cell types in cm scale specimens. This methodology represents a Rosetta Stone for biology that can cross-reference histology’s universal applications to biology and medicine with 3-dimensional anatomic context that can anchor for the full range of -omic technologies such as genomics, epigenomics, transcriptomics, proteomics, metabolomics. Basic science impacts include a reunification of biology, comprehensive studies of gene function through whole-organism phenotypic “signatures”, and the potential definition of the “Geometry of Life”, “Geometry of Disease”. Associated computational tools will create a uniquely broad foundation for translational applications as diverse as clinical diagnostics, validation of animal models of human disease, drug development, and environmental toxicology. In short, AI will be combined with unique and powerful new imaging capabilities at unprecedented combinations of scale and resolution. The approach will also be applicable to plant biology and to the physical sciences to advance fields including materials science, electronics, aerospace, and battery development.
            	</p>
		<strong>Speaker Bio:</strong>
                <span>Dr. Keith Cheng is interested in making fundamental contributions to the understanding of genetic and molecular mechanisms involved in human biology and disease. The lab is interested in genetic aspects of human disease, use of model systems such as the zebrafish, contribution to web-based scientific resources and new, potentially high-throughput forms of 3D imaging.
		Some of the Cheng lab's specific work is aimed at increasing understanding of the basis of phenotypic variability, particularly as it may impact cancer; basic mechanisms underlying the relationship between human skin pigmentation and skin cancer; contributing to web-based infrastructures for science, education and public service; and working toward a 3D derivative of histology that also allows the identification and characterization of all cell types but utilizes the computer to define slice angle, thickness, point of view and definition of tissues of interest. Obvious implications include automation of phenotyping, including diagnostics.
                <br>
		</span>
            
	    </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
                <p>  <strong>Talk Title:</strong>  Image-based Cell Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:00 PM EDT</span><br>
		<strong>Speaker:</strong>
                <span>Juan Caicedo, Ph.D., Broad Institute. </span> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/JuanCaicedo-bio.png" width="300" height="240">
		</center></p>
		<p>
           	<strong> Abstract:</strong> Visual cell phenotyping is the characterization and quantification of observable cellular traits in images. Recently, cellular phenotyping has undergone a massive overhaul in terms of the scale, resolution, and throughput, attributable to the advances across electronic, optical, and chemical technologies for imaging cells. Coupled with the rapid acceleration of deep-learning based computational tools, these advances have opened up new avenues for innovation across a wide variety of high-throughput cell biology applications. In this talk, we will review applications where deep learning is powering the recognition, profiling, and prediction of visual phenotypes to answer important biological questions. As the complexity and scale of imaging assays increase to understand biological models, deep learning offers computational solutions to improve our ability for studying more precise details of cellular phenotypes.
           
            	</p>
		<strong>Speaker Bio:</strong>
                <span>Juan C. Caicedo is a Schmidt Fellow at the Broad Institute of MIT and Harvard. He is pioneering the use of deep learning and machine learning methods to analyze microscopy images and high-resolution genetic data. He is also exploring reinforcement learning, a method of training algorithms to optimize biological experiments. He collaborates with the Cell Circuits and Epigenomics Programs and the Imaging Platform.
		Caicedo received his Ph.D. in computer engineering from the National University of Colombia. He completed internships at Google Research, Microsoft Research, and Queen Mary University of London as a grad student. As a postdoctoral researcher at the University of Illinois at Urbana-Champaign, he studied object detection problems in internet scale image collections with deep reinforcement learning.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>
                <p>  <strong>Talk Title:</strong>  What We’ve Learned from RxRx1 So Far: Cellular Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:40 PM EDT</span><br>
                <p><strong>Speaker:</strong>
                <span>Berton Earnshaw, Ph.D., Recursion Pharmaceuticals </span><strong></strong> </p>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Berton.jfif" width="300" height="300">
		</center></p>
           	<strong> Abstract:</strong> In 2019, Recursion released its first public dataset in the RxRx series called RxRx1. It consists of over 125,000 fluorescent microscopy images of siRNA-treated cells from more than 50 different executions of the same experiment design in four cell types. Over 1,100 different siRNA were used in the design, thus RxRx1 contains images of cells under a wide variety of genetic perturbations in a large number of experimental batches. Recursion subsequently hosted a competition on Kaggle challenging competitors to correctly classify these cellular phenotypes in batches held out from the training set, and the results were extraordinary – using deep learning, the winner achieved an average test accuracy of 99.763%! In this talk, I will describe some of the things we have learned about cellular phenotyping with deep learning from both this competition and our own internal research, and outline some of the ways we use such phenotypes for drug discovery and development.           
            	</p>
                <strong>Speaker Bio:</strong>
                <span>Berton Earnshaw is a Machine Learning Fellow at Recursion, where he directs the company’s strategy in applying AI to the company’s multi-petabyte cellular imaging data.  Berton earned a PhD in mathematics from the University of Utah, studying protein trafficking during memory formation, and was a postdoctoral fellow at the University of Utah and Michigan State University, where his research focused on nonautonomous master equations governing receptor kinetics.  Berton then worked in various technical and scientific roles in industry, including CTO of Perfect Pitch, Director of Data Science and Operations at Red Brain Labs, and principal and senior scientist at Savvysherpa (acquired by UnitedHealth Group).
                </span>
            </div>


            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
        	<p>  <strong>Talk Title:</strong>  Applications of AI to Elucidate Mechanisms of Neurodegenerative Disease in Models and Patients</p>
		<strong>Start Time: </strong><span>18:50 PM EDT</span><br>
        	<p> <strong>Speaker:</strong>
		<span>Steve Finkbeiner, M.D., Ph.D., University of California, San Francisco</span></p>
        	<p><center>
		<img class="img-responsive" alt="" src="./img/images/steve.jpg"  width="250" height="300">
		</center></p>
        
       		 <p>
       		<strong> Abstract:</strong> 
         	Neurodegenerative diseases, such as Alzheimer (AD) and Parkinson diseases (PD), are an enormous and growing unmet medical need throughout the world. Unfortunately and despite tremendous efforts, the causes of these disease in the majority of cases remains poorly understood, and the diseases remain incurably fatal. One reason that has been offered to explain the disappointing pace of progress is that these diseases are complex. Most cases are idiopathic, and the field still doesn’t know if clinical syndromes such as AD or PD each have a single cause or multiple causes requiring patient stratification and different therapeutic approaches.
To try to address the complexity of neurodegenerative disease, we have begun to develop and apply new artificial intelligence (AI) tools to data sets that are too big or too complex for humans to fully understand. In this talk, we will illustrate some of the new approaches to our imaging and genomic data to gain new insights from our model systems and patients. For example, we recently showed that we could use deep learning to train neural networks to accurately predict cell structures, cell state and cell function from images of unlabeled cells, something humans are unable to do without labeling. More recently, we have developed a series of AI tools to measure disease-relevant phenotypes from model systems such as patient-derived iPSCs. These include tools that track cells and detect some of the earliest signs of neuronal dysfunction, including changes in neurite morphology and the earliest time points at which neurons commit to undergo degeneration. We have built new robots and developed AI tools to also investigate neurobehavior in high throughput in simple genetic models, such as zebrafish. And recently, we have adapted machine learning tools to glean insights from whole genome sequence and pathology samples from patients with ALS, PD and AD. We are optimistic that new powerful AI-based tools have much to offer investigators trying to uncover the causes of complex neurodegenerative diseases and to eventually find therapies that will be effective.
          	</p>
          
		<strong>Speaker Bio: </strong>
		<span>Dr. Finkbeiner is best known for his pioneering work on brain disorders. He invented robotic microscopy, a new form of imaging that has helped unravel cause-and-effect relationships in amyotrophic lateral sclerosis (ALS, or Lou Gehrig’s disease), Huntington’s, Alzheimer’s, Parkinson’s, autism and schizophrenia. Dr. Finkbeiner used this technology to resolve a long-standing puzzle related to one disease, and a study based with this approach became the most-cited paper in the field of neuroscience of the last decade. The scope and scale of data produced with this approach has enabled the application of deep learning to address some of the critical obstacles to understanding and treating these brain diseases, including disease modeling, early diagnosis, patient stratification, and therapeutic discovery.
 		</span>


        </div>
<br>

    </div>
</body>

</html>