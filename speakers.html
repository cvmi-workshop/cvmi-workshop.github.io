<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Computer Vision for Microscopy Image Analysis 2021</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/speakers.css">
</head>

<body>
    <div class="headBox">
   <!--     <div class="imgBox">
            <img class="logoBox" src="img/images/Picture2.png" alt="">

        </div>  -->

        <div class="navBox">
            <ul>
                <li>
                    <a href="./new.html"><i><strong class="new">New</strong></i></a></li>
                <li>
                    <a href="index.html"><strong>Welcome</strong></a></li>
                <li>
                    <a href="organizers.html"><strong>Organizers</strong></a></li>
                <li>
                    <a href="speakers.html"><strong>Invited Speakers</strong></a></li>
		<li>
                    <a href="program.html"><strong>Program</strong></a></li>
		<li>
                    <a href="registration.html"><strong>Registration</strong></a></li>
                <li>
                    <a href="venue.html"><strong>Attend</strong></a></li>
                <li>
                    <a href="sponsor.html"><strong>Sponsors</strong></a></li>
		<li>
                    <a href="jobs.html"><strong>Jobs</strong></a></li>
		<li>
                    <a href="comittee.html"><strong>Program Committee</strong></a></li>
                <li>
                    <a href="callForPaper.html"><strong>Call for Papers</strong></a></li>
                <li>
                    <a href="dates.html"><strong>Important Dates</strong></a></li>
                <li>
                    <a href="submission.html"><strong>Submission</strong></a></li>
                <li>
                    <a href="accepted.html"><strong>Accepted Papers</strong></a></li>
		<li>
                    <a href="spotlight.html"><strong>Works-in-Progress</strong></a></li>
		<li>
                    <a href="https://motchallenge.net/data/CTMC-v1/" target="_blank"><strong>MOT Challenge</strong></a></li>

                <li>
                    <a href="contact.html"><strong>Contact</strong></a></li>
                <li>
                    <a href="pastcvmi.html"><strong>Past CVMIs</strong></a></li>
            </ul>
        </div>
    </div>

    <div class="contentBox">
        <div class="headImgBox">
            <img class="headImg" src="img/images/Picture20.png" alt="">
        </div>

        <div class="titleBox">
            <p style="font-size: 120%;font-weight: 700;">Invited Speakers</p>
        </div>
        <hr style="height:1px;border:none;border-top:1px solid #555555;">
        <div class="detailBox detailBoxSpeakers">

	  <div>
   <!--             <p>  <strong>Talk Title:</strong>  Molecular Simulation Meets Cryo Electron Tomography </p>
                <strong>Start Time: </strong><span>12:40 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Anne E. Carpenter, Ph.D., Broad Institute. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Anne.jpg" width="240" height="180">
		</center></p>
<!--		<strong> Abstract:</strong> Cryo electron tomography and molecular dynamics simulations perfectly complement each other. Electron tomograms provide us with a remarkably detailed, three-dimensional view of the molecular architecture of cells and viruses in situ, that is in the natural context; however, this view is essentially static and atomic resolution remains largely out of reach, in particular for dynamic biomolecular machineries. By contrast, molecular dynamics simulations naturally give us an atomistic view that includes dynamics, albeit in an idealized context. The synergistic potential of tomography and simulation can now be realized thanks to an increase in the resolution achievable by cryo electron tomography, a rapid growth in raw computational power, significant improvements in the quality of the potential energy functions entering classical molecular dynamics simulations, and the availability of simulation codes that can handle the complex molecular systems encountered in situ. With applications to the SARS-CoV-2 viral envelope and to cell-cell junctions, I will demonstrate how molecular simulations can be used to add detail and dynamics to electron tomographic.
		</p> -->
		<strong>Speaker Bio:</strong>
                <span>Anne Carpenter is senior director of the Imaging Platform at Broad Institute of MIT and Harvard, where she is also an institute scientist. With a strong background in cell biology, microscopy, and computational biology, her expertise is in developing and applying methods for extracting quantitative information from biological images, especially in a high-throughput manner.

Carpenter directs a team of biologists and computer scientists in developing image analysis and data exploration methods and software that are open source and freely available to the public. She and her team developed CellProfiler, the first open-source, high-throughput cell image analysis software. Carpenter is now a pioneer in image-based profiling, the extraction of rich, unbiased information from images for drug discovery, and functional genomics. She collaborates with dozens of biomedical research groups around the world to use image analysis to identify disease states, therapeutic potential, and gene function from microscopy images.

Carpenter is an NIH MIRA investigator, an NSF CAREER awardee, and has received recognition and research funding from numerous other groups including the Human Frontiers in Science program and the Howard Hughes Medical Institute. She was recently named to the top-100 list of AI Leaders in Drug Discovery and Healthcare by Deep Knowledge Analytics, and she is an honorary fellow of the Royal Microscopical Society.

Carpenter earned her B.S. from Purdue University and her Ph.D. from the University of Illinois at Urbana-Champaign.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    
	 <div>
<!--		<p>  <strong>Talk Title:</strong> AI – New Horizons for Histopathology</p>
                <strong>Start Time: </strong><span>13:20 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Kaupo Palo, Ph.D., PerkinElmer. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/kaupo.jpg" width="220" height="230">
		</center></p>
<!-- <strong> Abstract:</strong> Machine learning and image analysis allows to interrogate morphological patterns with a precision and accuracy that exceeds human performance. The talk will highlight recent results that demonstrate the possibility of identifying morphological correlates of molecular subtypes in colorectal cancer using histology alone. Not only will this technology open up new opportunities for cellular pathology, it will also provide new ways for introducing certain molecular tests into the clinical workflow. Combined with new tissue imaging technologies that can visualise multiple different proteins in the same tissue section we can now interrogate tissues with a depth and resolution that has not been possible before.  In addition, I outline efforts for improving the pathology workflows using AI.</p>
		-->
		<strong>Speaker Bio:</strong>
                <span>Kaupo Palo studied physics at Tartu University, Estonia. He received his PhD in theoretical physics in Uppsala University, Sweden in 1994. Kaupo held his position as post-doctoral fellow in CERN, Geneva in 1994-1996. Shortly after he joined Hamburg based biotech company Evotec to contribute to the technologies based on single molecule spectroscopy. While the pharmaceutical industry and research turned more towards cellular microscopy, the company started producing microscopes for high content screening. From 2007 he joined PerkinElmer through acquisition. Kaupo's work became more focused on image processing and image analysis.
He contributed in areas of microscope design such as designing pinhole pattern of Nipkow disks, using Penrose tiling for image registration, designed methods for image processing such as digital phase contrast, shading correction, and designed pipelines for image analysis from segmentation to quantitation. In recent years he has investigated opportunities offered by Deep Learning in areas of image processing, object segmentation and classification.</span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>
 <!--               <p>  <strong>Talk Title:</strong>  Computer Vision Opportunities for Analyzing the Spatial Topography of Gene Expression in the Human Brain </p>
		<strong>Start Time: </strong><span>14:50 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Michael Tangrea, Ph.D., Loyola University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/tangrea.jpg" width="220" height="220">
		</center></p>
<!--		<strong> Abstract:</strong> The spatial organization of the brain is fundamentally related to its function. Understanding complex brain disorders will require identifying cell types that make up the brain and ultimately linking functional correlates of individual cell classes with spatial topography. Emerging approaches like spatial transcriptomics (ST) can quantify RNA transcripts within tissue architecture (defined by histological images), thereby retaining both anatomical and transcriptome-scale molecular information. To further our understanding of gene expression within the context of the spatial organization of the human cortex, we used the 10x Genomics Visium platform, a novel barcoding-based transcriptome-wide ST technology that maps RNA-sequencing reads to specific positions on a histological image, to generate spatial maps of gene expression in the six-layered dorsolateral prefrontal cortex (DLPFC) of the adult human brain.: We show that Visium and its combined proteomics platform (Visium-IF) can identify gene expression with high spatial resolution within the architecture of the human cortex. We discuss computer vision opportunities for further integrating Visium gene expression and histology/fluorescence microscopy data for spatial and pathological registration of gene expression in the normal brain as well as the brains of individuals with complex brain disorders.
           	 </p>
		-->
		<strong>Speaker Bio:</strong>
                <span>Dr. Tangrea is an Endowed Professor in the Biology Department at Loyola University Maryland. He also works closely with the Center for Innovation and Entrepreneurship. Dr. Tangrea is a translational researcher who specializes in the development of novel pathology technologies that facilitate improved biomolecular analysis of tissue specimens for translational research, tissue diagnostics and precision medicine.
He is the inventor on multiple patents and author of over 40 scientific publications and
invited speaker to diverse, technical audiences. He is the Co-Founder of BioNavigators (formerly the Mid-Atlantic Biology Research and Career [MABRC] Network) and is a Mentor to Life Science start-ups.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
 
            <div>
<!--		<p>  <strong>Talk Title:</strong> Geometry of Life: Computational Organismal and Tissue Phenomics from X-ray Histotomography, Multiscale Multi-omics, and AI</p>
		<strong>Start Time: </strong><span>15:30 PM EDT</span><br>  -->
                <strong>Speaker:</strong>
                <span>He Wang, MD., Ph.D., Yale University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/wang.jpg" width="200" height="220">
		</center></p>
<!--		<strong> Abstract:</strong> We have taken a systems approach to filling a profound gap in science: the spatially-resolved integration of increasingly data-intensive -omics tools across molecular, cellular, and organismal length scales. This approach has four anchors: 1) The cell is the 3D unit of life. 2) Cell identity and their normal and disease states are recognizable through sub-micron features discernable within cm fields of view. 3) a new form of 3D tissue imaging based on microCT, x-ray histotomography, has been developed at Penn State that, like histology, allows us to “see” every cell type and tissue without anisotropic distortion, allowing the computational characterization of shape and volume of cells, tissues, and organs. 4) Machine learning and AI applied to x-ray histotomography will allow feature measurement, computer modeling of cells and tissues, and computational phenotyping. In short, it is becoming possible to define the “Geometry of Life” digitally to the cellular level. Based on these anchors, large-field, tissue and organismal imaging will be done in 3D with cellular (submicron voxel) resolution across all cell types in cm scale specimens. This methodology represents a Rosetta Stone for biology that can cross-reference histology’s universal applications to biology and medicine with 3-dimensional anatomic context that can anchor for the full range of -omic technologies such as genomics, epigenomics, transcriptomics, proteomics, metabolomics. Basic science impacts include a reunification of biology, comprehensive studies of gene function through whole-organism phenotypic “signatures”, and the potential definition of the “Geometry of Life”, “Geometry of Disease”. Associated computational tools will create a uniquely broad foundation for translational applications as diverse as clinical diagnostics, validation of animal models of human disease, drug development, and environmental toxicology. In short, AI will be combined with unique and powerful new imaging capabilities at unprecedented combinations of scale and resolution. The approach will also be applicable to plant biology and to the physical sciences to advance fields including materials science, electronics, aerospace, and battery development.
            	</p>  -->
		<strong>Speaker Bio:</strong>
                <span>Dr. He Wang has been an Associate Professor at Yale University School of Medicine, and the Director of anatomic and cytopathology since October 2020. He received his MD from China Medical University (Shenyang, China) and his PhD in experimental pathology from McGill University (Montreal, Canada). After completing his anatomic pathology residency at the University of Michigan (Ann Arbor), he spent 1 year as a surgical pathology fellow at Massachusetts General Hospital (Boston), Harvard University (Cambridge, Massachusetts), and 1 year as a cytopathology fellow at the Hospital of the University of Pennsylvania (Philadelphia). In 2013, he joined the faculty of Temple University (Philadelphia, Pennsylvania) as assistant professor and director of immunohistochemistry. In 2018, Dr Wang accepted a faculty position at Robert Wood Johnson Medical School, Rutgers University (New Brunswick, New Jersey), as associate professor, and served as director of head and neck pathology (2018–2020) and associate director of cytopathology (2018–2020).
Dr Wang is a member of the American Society of Cytopathology. He has authored approximately 50 original peer-reviewed manuscripts and 9 books or book chapters. His translational research laboratory is supported by the National Institutes of Health and industry collaborative grants.
                <br>
		</span>
            
	    </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
                <p>  <strong>Talk Title:</strong>  Image-based Cell Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:00 PM EDT</span><br>
		<strong>Speaker:</strong>
                <span>Juan Caicedo, Ph.D., Broad Institute. </span> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/JuanCaicedo-bio.png" width="300" height="240">
		</center></p>
		<p>
           	<strong> Abstract:</strong> Visual cell phenotyping is the characterization and quantification of observable cellular traits in images. Recently, cellular phenotyping has undergone a massive overhaul in terms of the scale, resolution, and throughput, attributable to the advances across electronic, optical, and chemical technologies for imaging cells. Coupled with the rapid acceleration of deep-learning based computational tools, these advances have opened up new avenues for innovation across a wide variety of high-throughput cell biology applications. In this talk, we will review applications where deep learning is powering the recognition, profiling, and prediction of visual phenotypes to answer important biological questions. As the complexity and scale of imaging assays increase to understand biological models, deep learning offers computational solutions to improve our ability for studying more precise details of cellular phenotypes.
           
            	</p>
		<strong>Speaker Bio:</strong>
                <span>Juan C. Caicedo is a Schmidt Fellow at the Broad Institute of MIT and Harvard. He is pioneering the use of deep learning and machine learning methods to analyze microscopy images and high-resolution genetic data. He is also exploring reinforcement learning, a method of training algorithms to optimize biological experiments. He collaborates with the Cell Circuits and Epigenomics Programs and the Imaging Platform.
		Caicedo received his Ph.D. in computer engineering from the National University of Colombia. He completed internships at Google Research, Microsoft Research, and Queen Mary University of London as a grad student. As a postdoctoral researcher at the University of Illinois at Urbana-Champaign, he studied object detection problems in internet scale image collections with deep reinforcement learning.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>
                <p>  <strong>Talk Title:</strong>  What We’ve Learned from RxRx1 So Far: Cellular Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:40 PM EDT</span><br>
                <p><strong>Speaker:</strong>
                <span>Berton Earnshaw, Ph.D., Recursion Pharmaceuticals </span><strong></strong> </p>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Berton.jfif" width="300" height="300">
		</center></p>
           	<strong> Abstract:</strong> In 2019, Recursion released its first public dataset in the RxRx series called RxRx1. It consists of over 125,000 fluorescent microscopy images of siRNA-treated cells from more than 50 different executions of the same experiment design in four cell types. Over 1,100 different siRNA were used in the design, thus RxRx1 contains images of cells under a wide variety of genetic perturbations in a large number of experimental batches. Recursion subsequently hosted a competition on Kaggle challenging competitors to correctly classify these cellular phenotypes in batches held out from the training set, and the results were extraordinary – using deep learning, the winner achieved an average test accuracy of 99.763%! In this talk, I will describe some of the things we have learned about cellular phenotyping with deep learning from both this competition and our own internal research, and outline some of the ways we use such phenotypes for drug discovery and development.           
            	</p>
                <strong>Speaker Bio:</strong>
                <span>Berton Earnshaw is a Machine Learning Fellow at Recursion, where he directs the company’s strategy in applying AI to the company’s multi-petabyte cellular imaging data.  Berton earned a PhD in mathematics from the University of Utah, studying protein trafficking during memory formation, and was a postdoctoral fellow at the University of Utah and Michigan State University, where his research focused on nonautonomous master equations governing receptor kinetics.  Berton then worked in various technical and scientific roles in industry, including CTO of Perfect Pitch, Director of Data Science and Operations at Red Brain Labs, and principal and senior scientist at Savvysherpa (acquired by UnitedHealth Group).
                </span>
            </div>


            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
        	<p>  <strong>Talk Title:</strong>  Applications of AI to Elucidate Mechanisms of Neurodegenerative Disease in Models and Patients</p>
		<strong>Start Time: </strong><span>18:50 PM EDT</span><br>
        	<p> <strong>Speaker:</strong>
		<span>Steve Finkbeiner, M.D., Ph.D., University of California, San Francisco</span></p>
        	<p><center>
		<img class="img-responsive" alt="" src="./img/images/steve.jpg"  width="250" height="300">
		</center></p>
        
       		 <p>
       		<strong> Abstract:</strong> 
         	Neurodegenerative diseases, such as Alzheimer (AD) and Parkinson diseases (PD), are an enormous and growing unmet medical need throughout the world. Unfortunately and despite tremendous efforts, the causes of these disease in the majority of cases remains poorly understood, and the diseases remain incurably fatal. One reason that has been offered to explain the disappointing pace of progress is that these diseases are complex. Most cases are idiopathic, and the field still doesn’t know if clinical syndromes such as AD or PD each have a single cause or multiple causes requiring patient stratification and different therapeutic approaches.
To try to address the complexity of neurodegenerative disease, we have begun to develop and apply new artificial intelligence (AI) tools to data sets that are too big or too complex for humans to fully understand. In this talk, we will illustrate some of the new approaches to our imaging and genomic data to gain new insights from our model systems and patients. For example, we recently showed that we could use deep learning to train neural networks to accurately predict cell structures, cell state and cell function from images of unlabeled cells, something humans are unable to do without labeling. More recently, we have developed a series of AI tools to measure disease-relevant phenotypes from model systems such as patient-derived iPSCs. These include tools that track cells and detect some of the earliest signs of neuronal dysfunction, including changes in neurite morphology and the earliest time points at which neurons commit to undergo degeneration. We have built new robots and developed AI tools to also investigate neurobehavior in high throughput in simple genetic models, such as zebrafish. And recently, we have adapted machine learning tools to glean insights from whole genome sequence and pathology samples from patients with ALS, PD and AD. We are optimistic that new powerful AI-based tools have much to offer investigators trying to uncover the causes of complex neurodegenerative diseases and to eventually find therapies that will be effective.
          	</p>
          
		<strong>Speaker Bio: </strong>
		<span>Dr. Finkbeiner is best known for his pioneering work on brain disorders. He invented robotic microscopy, a new form of imaging that has helped unravel cause-and-effect relationships in amyotrophic lateral sclerosis (ALS, or Lou Gehrig’s disease), Huntington’s, Alzheimer’s, Parkinson’s, autism and schizophrenia. Dr. Finkbeiner used this technology to resolve a long-standing puzzle related to one disease, and a study based with this approach became the most-cited paper in the field of neuroscience of the last decade. The scope and scale of data produced with this approach has enabled the application of deep learning to address some of the critical obstacles to understanding and treating these brain diseases, including disease modeling, early diagnosis, patient stratification, and therapeutic discovery.
 		</span>
-->

        </div>
<br>

    </div>
</body>

</html>