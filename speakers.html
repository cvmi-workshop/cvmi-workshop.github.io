<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Computer Vision for Microscopy Image Analysis 2021</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/speakers.css">
</head>

<body>
    <div class="headBox">
   <!--     <div class="imgBox">
            <img class="logoBox" src="img/images/Picture2.png" alt="">

        </div>  -->

        <div class="navBox">
            <ul>
                <li>
                    <a href="./new.html"><i><strong class="new">New</strong></i></a></li>
                <li>
                    <a href="index.html"><strong>Welcome</strong></a></li>
                <li>
                    <a href="organizers.html"><strong>Organizers</strong></a></li>
                <li>
                    <a href="speakers.html"><strong>Invited Speakers</strong></a></li>
		<li>
                    <a href="program.html"><strong>Program</strong></a></li>
		<li>
                    <a href="registration.html"><strong>Registration</strong></a></li>
                <li>
                    <a href="venue.html"><strong>Attend</strong></a></li>
                <li>
                    <a href="sponsor.html"><strong>Sponsors</strong></a></li>
		<li>
                    <a href="jobs.html"><strong>Jobs</strong></a></li>
		<li>
                    <a href="comittee.html"><strong>Program Committee</strong></a></li>
                <li>
                    <a href="callForPaper.html"><strong>Call for Papers</strong></a></li>
                <li>
                    <a href="dates.html"><strong>Important Dates</strong></a></li>
                <li>
                    <a href="submission.html"><strong>Submission</strong></a></li>
                <li>
                    <a href="accepted.html"><strong>Accepted Papers</strong></a></li>
		<li>
                    <a href="spotlight.html"><strong>Works-in-Progress</strong></a></li>
		<li>
                    <a href="https://motchallenge.net/data/CTMC-v1/" target="_blank"><strong>CTMC Challenge</strong></a></li>

                <li>
                    <a href="contact.html"><strong>Contact</strong></a></li>
                <li>
                    <a href="pastcvmi.html"><strong>Past CVMIs</strong></a></li>
            </ul>
        </div>
    </div>

    <div class="contentBox">
        <div class="headImgBox">
            <img class="headImg" src="img/images/Picture22.png" alt="">
        </div>

        <div class="titleBox">
            <p style="font-size: 120%;font-weight: 700;">Invited Speakers</p>
        </div>
        <hr style="height:1px;border:none;border-top:1px solid #555555;">
      <div class="detailBox detailBoxSpeakers">

	  <div>
  <!--      <p>  <strong>Talk Title:</strong> Information in images for drug discovery: image-based profiling </p>
             <strong>Start Time: </strong><span>9:40 AM CDT</span><br>		-->
		<strong>Speaker:</strong>
                <span>Inti Zlobec, Professor, University of Bern. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Inti.png" width="210" height="240">
		</center></p>
	<!--	<strong> Abstract:</strong> Cell images contain a vast amount of quantifiable information about the status of the cell: for example, whether it is diseased, whether it is responding to a drug treatment, or whether a pathway has been disrupted by a genetic mutation. We extract hundreds of features of cells from images. Just like transcriptional profiling, the similarities and differences in the patterns of extracted features reveal connections among diseases, drugs, and genes. Improving this pipeline is an active area of research, from feature extraction to batch correction to quality control to assessing similarities.

We are harvesting similarities in image-based profiles to identify, at a single-cell level, how diseases, drugs, and genes affect cells, which can uncover small molecules’ mechanism of action, discover gene functions, predict assay outcomes, discover disease-associated phenotypes, identify the functional impact of disease-associated alleles, and find novel therapeutic candidates. As part of the JUMP-Cell Painting Consortium (Joint Undertaking for Morphological Profiling-Cell Painting) we are aiming to establish experimental and computational best practices for image-based profiling (https://jump-cellpainting.broadinstitute.org/results) and produce the world’s largest public Cell Painting gene/compound image resource, with 140,000 perturbations in five replicates, to be released November 2022. With these data and new technologies like Pooled Cell Painting and variants of the assay like LipocyteProfiler and CardioProfiler, we hope to bring drug discovery-accelerating applications to practice.
		</p>	-->
		<strong>Speaker Bio:</strong>
                <span>Inti Zlobec holds the position of Professor (Extraordinarius) of Digital Pathology at the Institute of Pathology, University of Bern, Switzerland. She graduated with a PhD degree in Experimental Pathology, from McGill University, Montreal, Canada in 2007 before completing a post-doctoral fellowship at the Institute of Pathology, University Hospital Basel, where she conducted tissue-based research in the field of colorectal cancer using biostatistical models. After habilitating in 2010, she received a position at the Institute of Pathology, University of Bern, where she established and led the Translational Research Unit (TRU) and later the Tissue Bank Bern (TBB). Inti Zlobec became Associate Professor in 2014. Now, she leads an inter-disciplinary research group of students and researchers using artificial intelligence and machine learning as tools to study pathology images along with other data types to discover and validate novel prognostic and predictive biomarkers for colorectal cancer patients. Inti Zlobec is a member of the Executive Team of the Center for Artificial Intelligence in Medicine (CAIM) of the University of Bern, Co-Founder and President of the Swiss Consortium for Digital Pathology (SDiPath) and Chair of the European Society of Pathology (ESP) Working Group IT.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	      <div>

<!--		<p>  <strong>Talk Title:</strong>Deep Learning for bright field image analysis</p>
                 <strong>Start Time: </strong><span>10:20 AM CDT</span><br>	-->
		<strong>Speaker:</strong>
                <span>Jeroen van der Laak, Professor, Radboud University Medical Center. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Jeroen.jpg" width="210" height="220">
		</center></p>
<!--		<strong> Abstract:</strong> Common fluorescence microscopes come with the capability to acquire images in bright field.  While fluorescence is a powerful method to extract information on cellular pathways, bright field is a universal label free imaging method having its strength when less invasive method is needed.  It is ideal for measuring live cell cultures in dynamics like stem cells, and cardiomyocytes. The drawback of bright field is significantly more complex image structure, susceptibility to artifacts, and less specific signal compared to multichannel fluorescence readouts.  We will discuss the possibilities opened by Deep Learning for bright field cellular image analysis.
		</p>		-->
<strong>Speaker Bio:</strong>
                <span>Jeroen van der Laak is professor in Computational Pathology and principle investigator at the Department of Pathology of Radboud University Medical Center in Nijmegen, The Netherlands and guest professor at the Center for Medical Image Science and Visualization (CMIV) in Linköping, Sweden. His research group investigates the use of deep learning-based whole-slide image analysis for different applications; improvement of routine pathology diagnostics, objective quantification of immunohistochemical markers, and study of novel imaging biomarkers for prognostics. Jeroen has an MSc in Computer science and acquired his PhD from Radboud University in Nijmegen. He co-authored over 125 peer-reviewed publications and is a member of the editorial boards of Modern Pathology, Laboratory Investigation and the Journal of Pathology Informatics. He is chair of the taskforce ‘AI in Pathology’ of the European Society of Pathology, member of the board of directors of the Digital Pathology Association and organizer of the Computational Pathology Symposium at the European Congress of Pathology. He coordinated the CAMELYON grand challenges in 2016 and 2017. Jeroen van der Laak acquired research grants from the European Union and the Dutch Cancer Society, among others. Jeroen is coordinator of the Bigpicture consortium and USCAP Nathan Kaufman lecture laureate.</span>
            </div>


         <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
<!--        	<p>  <strong>Talk Title:</strong>From cells to animals: new tools for 3D computer vision in life sciences</p>
		<strong>Start Time: </strong><span>11:40 AM CDT</span><br>	-->
        	<p> <strong>Speaker:</strong>
		<span>Faisal Mahmood, Associate Professor, Harvard Medical School.</span></p>
        	<p><center>
		<img class="img-responsive" alt="" src="./img/images/Faisal.jpg"  width="220" height="220">
		</center></p>
        
       		 <p>
 <!--    		<strong> Abstract:</strong> 
         	One of the key questions in neuroscience is linking cellular insights to behavior. This requires studying the nervous system across scales. In my talk I will discuss our efforts at building robust and scalable AI-based tools for measuring dynamics across scales: from cell-tracking in a dish, 3D segmentation and analytics, to whole organisms. In particular, I will highlight our line of work on DeepLabCut, a computer vision toolbox for pose estimation and new work on 3D cell segmentation on cleared whole-brain tissue. 
          	</p>		-->
          
		<strong>Speaker Bio: </strong>
		<span>Dr. Mahmood is an Associate Professor of Pathology at Harvard Medical School and the Division of Computational Pathology at the Brigham and Women's Hospital. He received his Ph.D. in Biomedical Imaging from the Okinawa Institute of Science and Technology, Japan and was a postdoctoral fellow at the department of biomedical engineering at Johns Hopkins University. His research interests include pathology image analysis, morphological feature, and biomarker discovery using data fusion and multimodal analysis. Dr. Mahmood is a full member of the Dana-Farber Cancer Institute / Harvard Cancer Center; an Associate Member of the Broad Institute of Harvard and MIT, and a member of the Harvard Bioinformatics and Integrative Genomics (BIG) faculty.</span>


            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>

<!--		<p>  <strong>Talk Title:</strong> Traditional and Deep Learning Models of Cellular Structure </p>
	 		<strong>Start Time: </strong><span>13:20 PM CDT</span><br>	-->
                <strong>Speaker:</strong>
                <span>Fabian Theis, Professor, Technische Universität München. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Fabian.jpg" width="200" height="230">
		</center></p>
	<!--	<strong> Abstract:</strong> A major challenge in computer vision applications in microscopy is creating accurate models of cell structures. Cells have a higher degree of stochasticity and a larger number of components than most subjects of computer vision applications, even higher than other natural objects like plants and animals, complicating use of both traditional and deep learning methods.  Most cellular components are distinct objects with defined boundaries that do not overlap.  Thus challenges include not only segmentation and scene parsing but also construction of generative models that are object-based.  Our work on this subject using traditional methods introduced the idea of constructing objects whose position within the cell was conditional upon other parts, such as the cell membranes, nuclear membranes and microtubules.  With the advent of deep learning and the creation by the Allen Institute of large 3D image collections in which particular organelles were fluorescently-labeled, a significant advance occurred through the creation of conditional autoencoder models for organelles.  A second advance occurred with using a U-net approach to make these models to all be conditional upon a common reference, unlabeled image, which allowed the relationships between different organelles to be at least partially inferred.  We have developed an alternative GAN-based approach and have evaluated how well both models preserve the expected property that organelles do not overlap.  We then developed a modified loss function that allows retraining of the models to minimize that overlap.  We have also developed approaches using our object-based modeling system to evaluate how well synthetic images capture object shape and spatial distribution.
            </p>  	-->
		<strong>Speaker Bio:</strong>
                <span>Fabian Theis is a pioneer in biomedical AI and machine learning, in particular in the context of single-cell biology. He focuses on preprocessing, visualizing, and modeling heterogeneities based on single-cell genomics providing methods and tools with a broad user-base.
Fabian is head of the Institute of Computational Biology at Helmholtz Munich and full professor at the Technical University of Munich, holding the chair ‘Mathematical Modelling of Biological Systems’. Since 2018 he has been coordinator of the Munich School for Data Science and since 2019 director of the Helmholtz Artificial Intelligence Cooperation Unit (HelmholtzAI). He is involved and coordinates several relevant networks including the Single Cell Omics Network Germany..

            <br>
		</span>  
	      </div>

    	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>

 <!--           <p>  <strong>Talk Title:</strong>Adaptation of Digital Pathology to Tissue Microdissection</p>
			<strong>Start Time: </strong><span>14:30 PM CDT</span><br>		-->
		<strong>Speaker:</strong>
                <span>Jocelyn Kishi, PhD, CEO & Co-Founder, Stealth TechBio Startup. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Josie.jpg" width="220" height="220">
		</center></p>
<!--		<strong> Abstract:</strong> Digital pathology applications have increased dramatically over the past five years, with several clinically validated image analysis tools now making an impact on patient care.  Yet, some microscope-based technologies, such as laser microdissection have been slow to embrace these innovative solutions.  Working with a group of collaborators, we adapted several image analysis tools: probabilistic pairwise Markov model (PPMM), ImageJ, spatially invariant vector quantization (SIVQ), and eSeg into the microdissection workflow. Using both the ThermoFisher Scientific ArcturusXT and Leica LMD7000 microdissection platforms, we developed protocols to incorporate these image analysis tools to isolate specific targets within the heterogenous tissue section. This new approach has been coined “computer-aided laser dissection” or “CALD”.  Although at an early-stage, the method may facilitate both research projects and clinical applications in the future.</p>
		-->
		<strong>Speaker Bio:</strong>
                <span>Dr. Kishi’s research focuses on developing new methods for reading and writing DNA sequences, DNA computing and molecular robotics, and DNA-based imaging assays. My background in software engineering has allowed me to work on projects at the intersection of Computer Science and DNA Nanotechnology.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>

 <!--         <p>  <strong>Talk Title:</strong>  Towards AI-driven Cancer Data Integration: Perspectives from Histopathology and Molecular Profiles </p>
               <strong>Start Time: </strong><span>16:15 PM CDT</span><br>	-->
		<strong>Speaker:</strong>
                <span>Michael J Keiser, Associated Professor, UC San Francisco. </span> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Keiser.jpg" width="200" height="220">
		</center></p>
		<p>
 <!--        	<strong> Abstract:</strong> The interplay of digital histopathological images and molecular data offers new perspectives to advance clinical decision making in cancer. In this talk, I will highlight the recent surge of histopathology-based AI analytics for predicting multiple cancer molecular outcomes. First, I will present recent deep-learning works on linking whole slide images and important mutational outcomes in breast cancer and its validations across cancer types. We provide an image-to-genomics pipeline to allow a head-to-head comparison between mutations and biological pathway signals by leveraging public cohorts. Second, I will share our research progress on developing graph-based deep learning classifiers to predict genetic mutations in colon cancer. Finally, ongoing data challenges, limitations, and research opportunities will be discussed in related areas.
            	</p>	-->
		<strong>Speaker Bio:</strong>
                <span>As a National Science Foundation Fellow, Dr. Keiser earned a PhD in bioinformatics in 2009 from UCSF, where he developed techniques, such as the Similarity Ensemble Approach (SEA), to relate drugs and proteins based on the statistical similarity of their ligands. Dr. Keiser also holds BSc, BA, and MA degrees from Stanford University. He subsequently cofounded a startup that brings these methods to pharmaceutical companies and to the US FDA. Dr. Keiser joined the faculty at UCSF in the Department of Pharmaceutical Chemistry and the IND in 2014, with a joint appointment in the Department of Bioengineering and Therapeutic Sciences. His lab investigates forward polypharmacology for complex diseases and the prediction of drug off-target activities.
The Keiser lab combines machine learning and chemical biology methods to investigate how small molecules perturb entire protein networks to achieve their therapeutic effects. In classical pharmacology, each drug was thought to strike a single note (in other words, "one drug hits one target to treat one disease"). However, it has been discovered that some drugs strike entire "chords" of targets at once, and this can be essential to their action. The Keiser group is tracing out this molecular music, not only in terms of new and useful therapeutic chords to treat neurodegenerative diseases, but also to identify the jarring notes that some drugs might unintentionally hit when they induce side effects
.   </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>

 <!--           <p>  	<strong>Talk Title:</strong>Transforming Pathology Using Digital Platforms and Deep Learning</p>
            	<strong>Start Time: </strong><span>17:25 PM CDT</span><br>	-->
                <p><strong>Speaker:</strong> 	
                <span>Po-Hsuan Cameron Chen, Ph.D., Google Health</span><strong></strong> </p>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Cameron.jpg" width="200" height="200">
		</center></p>
<!--           	<strong> Abstract:</strong> Ruijin Hospital has been consistently ranked 4th in China for over 6 years, and it has been the best hospital in Shanghai for quite a while. In its Department of Pathology, dealing with more than 3,000 patients per day, the pathologists send pathology reports to the doctors within 5 business days after the biopsy or surgery is performed, which can be accelerated with advanced techniques and platforms.
 
We have been collaborating with Ruijin Hospital in developing an AI-assisted pathology analysis system for the screening of malignant cases, lesions localization, and quantitative analysis. 
The optimized workflow has the following steps: 1) scanning pathology slides with high-throughput pathology digital scanners; 2) storing the digital images and processing them with the designed system on our platform; 3) providing the model-generated results to pathologists for further diagnosis.
After two years of refinement in Ruijin Hospital, the whole diagnostic process is shortened to 2 business days with nearly 100% sensitivity and over 80% specificity. 
 
We also organized a MICCAI Grand Challenge called DigestPath on MICCAI2019, which released the largest dataset (1,200 images from 540 patients) in gastrointestinal pathology, encouraging more participants in related fields.
 
In the future, we plan to focus on the research and landing of multi-center, multi-style, and multi-dimensional composite supervised learning in the field of pathology with more collaborators.           
            	</p>	-->
                <strong>Speaker Bio:</strong>
                <span>Po-Hsuan Cameron Chen is a staff software engineer and a tech lead manager of machine learning at Google Health. His primary research interests lie in the intersection of machine learning, healthcare, and science. His research has been published in leading scientific, clinical and machine learning venues, including Nature, JAMA, and NeurIPS, and covered by media outlets such as the New York Times, Forbes, and Engadget. Before Google, he did his PhD in Electrical Engineering and Neuroscience at Princeton University and received BS in Electrical Engineering from National Taiwan University. He has worked on several theoretical or applied machine learning projects in various domains, including finance, forecasting, operation research, at Princeton, Amazon, Palantir, Intel Labs and Vatic Labs. He was also a recipient of the Google PhD Fellowship.</span>
            </div>



        </div>
<br>

    </div> -->
</body>

</html>