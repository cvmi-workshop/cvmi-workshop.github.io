<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Computer Vision for Microscopy Image Analysis 2021</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/speakers.css">
</head>

<body>
    <div class="headBox">
   <!--     <div class="imgBox">
            <img class="logoBox" src="img/images/Picture2.png" alt="">

        </div>  -->

        <div class="navBox">
            <ul>
                <li>
                    <a href="./new.html"><i><strong class="new">New</strong></i></a></li>
                <li>
                    <a href="index.html"><strong>Welcome</strong></a></li>
                <li>
                    <a href="organizers.html"><strong>Organizers</strong></a></li>
                <li>
                    <a href="speakers.html"><strong>Invited Speakers</strong></a></li>
		<li>
                    <a href="program.html"><strong>Program</strong></a></li>
		<li>
                    <a href="registration.html"><strong>Registration</strong></a></li>
                <li>
                    <a href="venue.html"><strong>Attend</strong></a></li>
                <li>
                    <a href="sponsor.html"><strong>Sponsors</strong></a></li>
		<li>
                    <a href="jobs.html"><strong>Jobs</strong></a></li>
		<li>
                    <a href="comittee.html"><strong>Program Committee</strong></a></li>
                <li>
                    <a href="callForPaper.html"><strong>Call for Papers</strong></a></li>
                <li>
                    <a href="dates.html"><strong>Important Dates</strong></a></li>
                <li>
                    <a href="submission.html"><strong>Submission</strong></a></li>
                <li>
                    <a href="accepted.html"><strong>Accepted Papers</strong></a></li>
		<li>
                    <a href="spotlight.html"><strong>Works-in-Progress</strong></a></li>
		<li>
                    <a href="https://motchallenge.net/data/CTMC-v1/" target="_blank"><strong>MOT Challenge</strong></a></li>

                <li>
                    <a href="contact.html"><strong>Contact</strong></a></li>
                <li>
                    <a href="pastcvmi.html"><strong>Past CVMIs</strong></a></li>
            </ul>
        </div>
    </div>

    <div class="contentBox">
        <div class="headImgBox">
            <img class="headImg" src="img/images/Picture20.png" alt="">
        </div>

        <div class="titleBox">
            <p style="font-size: 120%;font-weight: 700;">Invited Speakers</p>
        </div>
        <hr style="height:1px;border:none;border-top:1px solid #555555;">
        <div class="detailBox detailBoxSpeakers">

	  <div>
        <p>  <strong>Talk Title:</strong> Information in images for drug discovery: image-based profiling </p>
  <!--              <strong>Start Time: </strong><span>12:40 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Anne E. Carpenter, Ph.D., Broad Institute of Harvard and MIT. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Anne.jpg" width="240" height="180">
		</center></p>
		<strong> Abstract:</strong> Cell images contain a vast amount of quantifiable information about the status of the cell: for example, whether it is diseased, whether it is responding to a drug treatment, or whether a pathway has been disrupted by a genetic mutation. We extract hundreds of features of cells from images. Just like transcriptional profiling, the similarities and differences in the patterns of extracted features reveal connections among diseases, drugs, and genes. Improving this pipeline is an active area of research, from feature extraction to batch correction to quality control to assessing similarities.

We are harvesting similarities in image-based profiles to identify, at a single-cell level, how diseases, drugs, and genes affect cells, which can uncover small molecules’ mechanism of action, discover gene functions, predict assay outcomes, discover disease-associated phenotypes, identify the functional impact of disease-associated alleles, and find novel therapeutic candidates. As part of the JUMP-Cell Painting Consortium (Joint Undertaking for Morphological Profiling-Cell Painting) we are aiming to establish experimental and computational best practices for image-based profiling (https://jump-cellpainting.broadinstitute.org/results) and produce the world’s largest public Cell Painting gene/compound image resource, with 140,000 perturbations in five replicates, to be released November 2022. With these data and new technologies like Pooled Cell Painting and variants of the assay like LipocyteProfiler and CardioProfiler, we hope to bring drug discovery-accelerating applications to practice.
		</p>
		<strong>Speaker Bio:</strong>
                <span>Anne Carpenter is senior director of the Imaging Platform at Broad Institute of MIT and Harvard, where she is also an institute scientist. With a strong background in cell biology, microscopy, and computational biology, her expertise is in developing and applying methods for extracting quantitative information from biological images, especially in a high-throughput manner.

Carpenter directs a team of biologists and computer scientists in developing image analysis and data exploration methods and software that are open source and freely available to the public. She and her team developed CellProfiler, the first open-source, high-throughput cell image analysis software. Carpenter is now a pioneer in image-based profiling, the extraction of rich, unbiased information from images for drug discovery, and functional genomics. She collaborates with dozens of biomedical research groups around the world to use image analysis to identify disease states, therapeutic potential, and gene function from microscopy images.

Carpenter is an NIH MIRA investigator, an NSF CAREER awardee, and has received recognition and research funding from numerous other groups including the Human Frontiers in Science program and the Howard Hughes Medical Institute. She was recently named to the top-100 list of AI Leaders in Drug Discovery and Healthcare by Deep Knowledge Analytics, and she is an honorary fellow of the Royal Microscopical Society.

Carpenter earned her B.S. from Purdue University and her Ph.D. from the University of Illinois at Urbana-Champaign.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	      <div>

		<p>  <strong>Talk Title:</strong>Deep Learning for bright field image analysis</p>
         <!--       <strong>Start Time: </strong><span>13:20 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Kaupo Palo, Ph.D., PerkinElmer. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/kaupo.jpg" width="210" height="220">
		</center></p>
		<strong> Abstract:</strong> Common fluorescence microscopes come with the capability to acquire images in bright field.  While fluorescence is a powerful method to extract information on cellular pathways, bright field is a universal label free imaging method having its strength when less invasive method is needed.  It is ideal for measuring live cell cultures in dynamics like stem cells, and cardiomyocytes. The drawback of bright field is significantly more complex image structure, susceptibility to artifacts, and less specific signal compared to multichannel fluorescence readouts.  We will discuss the possibilities opened by Deep Learning for bright field cellular image analysis.
		</p>		
<strong>Speaker Bio:</strong>
                <span>Kaupo Palo studied physics at Tartu University, Estonia. He received his PhD in theoretical physics in Uppsala University, Sweden in 1994. Kaupo held his position as post-doctoral fellow in CERN, Geneva in 1994-1996. Shortly after he joined Hamburg based biotech company Evotec to contribute to the technologies based on single molecule spectroscopy. While the pharmaceutical industry and research turned more towards cellular microscopy, the company started producing microscopes for high content screening. From 2007 he joined PerkinElmer through acquisition. Kaupo's work became more focused on image processing and image analysis.
He contributed in areas of microscope design such as designing pinhole pattern of Nipkow disks, using Penrose tiling for image registration, designed methods for image processing such as digital phase contrast, shading correction, and designed pipelines for image analysis from segmentation to quantitation. In recent years he has investigated opportunities offered by Deep Learning in areas of image processing, object segmentation and classification.</span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>

		<p>  <strong>Talk Title:</strong> Traditional and Deep Learning Models of Cellular Structure </p>
	<!--	<strong>Start Time: </strong><span>15:30 PM EDT</span><br>  -->
                <strong>Speaker:</strong>
                <span>Robert Murphy, Ph.D., Carnegie Mellon University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/murphy.jpg" width="200" height="230">
		</center></p>
		<strong> Abstract:</strong> A major challenge in computer vision applications in microscopy is creating accurate models of cell structures. Cells have a higher degree of stochasticity and a larger number of components than most subjects of computer vision applications, even higher than other natural objects like plants and animals, complicating use of both traditional and deep learning methods.  Most cellular components are distinct objects with defined boundaries that do not overlap.  Thus challenges include not only segmentation and scene parsing but also construction of generative models that are object-based.  Our work on this subject using traditional methods introduced the idea of constructing objects whose position within the cell was conditional upon other parts, such as the cell membranes, nuclear membranes and microtubules.  With the advent of deep learning and the creation by the Allen Institute of large 3D image collections in which particular organelles were fluorescently-labeled, a significant advance occurred through the creation of conditional autoencoder models for organelles.  A second advance occurred with using a U-net approach to make these models to all be conditional upon a common reference, unlabeled image, which allowed the relationships between different organelles to be at least partially inferred.  We have developed an alternative GAN-based approach and have evaluated how well both models preserve the expected property that organelles do not overlap.  We then developed a modified loss function that allows retraining of the models to minimize that overlap.  We have also developed approaches using our object-based modeling system to evaluate how well synthetic images capture object shape and spatial distribution.
            </p>  
		<strong>Speaker Bio:</strong>
                <span>Robert F. Murphy is Professor of Computational Biology Emeritus in the School of Computer Science at Carnegie Mellon University.  He was the Ray and Stephanie Lane Professor of Computational Biology and Professor of Biological Sciences, Biomedical Engineering, and Machine Learning at Carnegie Mellon until his retirement in May 2021.  He founded the Computational Biology Department in the School of Computer Science and served as its head from 2009 to 2020.  He is a Fellow of the IEEE and of the American Institute of Medical and Biological Engineering.
Dr. Murphy’s career has centered on combining cell measurements with quantitative and computational methods. In the mid 1990’s, his group pioneered the application of machine learning methods to high-resolution fluorescence microscope images depicting subcellular location patterns, and was the first to demonstrate superior machine performance in interpreting diverse patterns in biological images compared to human interpretation.  His main areas of focus are computer vision methods for biomedical image analysis and AI systems for autonomously driving closed-loop experimental science campaigns.

            <br>
		</span>  
	      </div>

    	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>

            <p>  <strong>Talk Title:</strong>Adaptation of Digital Pathology to Tissue Microdissection</p>
		<!-- <strong>Start Time: </strong><span>14:50 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Michael Tangrea, Ph.D., Loyola University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/tangrea.jpg" width="160" height="220">
		</center></p>
		<strong> Abstract:</strong> Digital pathology applications have increased dramatically over the past five years, with several clinically validated image analysis tools now making an impact on patient care.  Yet, some microscope-based technologies, such as laser microdissection have been slow to embrace these innovative solutions.  Working with a group of collaborators, we adapted several image analysis tools: probabilistic pairwise Markov model (PPMM), ImageJ, spatially invariant vector quantization (SIVQ), and eSeg into the microdissection workflow. Using both the ThermoFisher Scientific ArcturusXT and Leica LMD7000 microdissection platforms, we developed protocols to incorporate these image analysis tools to isolate specific targets within the heterogenous tissue section. This new approach has been coined “computer-aided laser dissection” or “CALD”.  Although at an early-stage, the method may facilitate both research projects and clinical applications in the future.</p>
		
		<strong>Speaker Bio:</strong>
                <span>Dr. Tangrea is an Endowed Professor in the Biology Department at Loyola University Maryland. He also works closely with the Center for Innovation and Entrepreneurship. Dr. Tangrea is a translational researcher who specializes in the development of novel pathology technologies that facilitate improved biomolecular analysis of tissue specimens for translational research, tissue diagnostics and precision medicine.
He is the inventor on multiple patents and author of over 40 scientific publications and
invited speaker to diverse, technical audiences. He is the Co-Founder of BioNavigators (formerly the Mid-Atlantic Biology Research and Career [MABRC] Network) and is a Mentor to Life Science start-ups.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>

          <p>  <strong>Talk Title:</strong>  Towards AI-driven Cancer Data Integration: Perspectives from Histopathology and Molecular Profiles </p>
   <!--             <strong>Start Time: </strong><span>17:00 PM EDT</span><br>  -->
		<strong>Speaker:</strong>
                <span>Mu Zhou, Ph.D., Stanford University. </span> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/muzhou.jpg" width="200" height="220">
		</center></p>
		<p>
         	<strong> Abstract:</strong> The interplay of digital histopathological images and molecular data offers new perspectives to advance clinical decision making in cancer. In this talk, I will highlight the recent surge of histopathology-based AI analytics for predicting multiple cancer molecular outcomes. First, I will present recent deep-learning works on linking whole slide images and important mutational outcomes in breast cancer and its validations across cancer types. We provide an image-to-genomics pipeline to allow a head-to-head comparison between mutations and biological pathway signals by leveraging public cohorts. Second, I will share our research progress on developing graph-based deep learning classifiers to predict genetic mutations in colon cancer. Finally, ongoing data challenges, limitations, and research opportunities will be discussed in related areas.
            	</p>
		<strong>Speaker Bio:</strong>
                <span>Dr. Mu Zhou is interested in machine learning, medical image analysis, and bioinformatics. Dr. Zhou serves as head for AI drug discovery at SenseBrain research, San Jose. He develops data-centered approaches to analyze and process quantitative information from multi-scale biomedical data across radiology, histopathology, and omics profiles in oncology. These findings enable early detection of disease, outcome prediction, and medical decision support for patients. He was a research scientist and a postdoctoral fellow at medical school, Stanford University. In collaboration with his colleagues, he led the research for linking cancer imaging and high-throughput RNA expression in lung cancer. He received his Ph.D. degree in computer science and engineering from University of South Florida, Tampa, where he pioneered radiomics analysis for non-invasive outcome prediction of cancer patients.   </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>

 <!--               <p>  <strong>Talk Title:</strong>  What We’ve Learned from RxRx1 So Far: Cellular Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:40 PM EDT</span><br>
                <p><strong>Speaker:</strong>
                <span>Berton Earnshaw, Ph.D., Recursion Pharmaceuticals </span><strong></strong> </p>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Berton.jfif" width="300" height="300">
		</center></p>
           	<strong> Abstract:</strong> In 2019, Recursion released its first public dataset in the RxRx series called RxRx1. It consists of over 125,000 fluorescent microscopy images of siRNA-treated cells from more than 50 different executions of the same experiment design in four cell types. Over 1,100 different siRNA were used in the design, thus RxRx1 contains images of cells under a wide variety of genetic perturbations in a large number of experimental batches. Recursion subsequently hosted a competition on Kaggle challenging competitors to correctly classify these cellular phenotypes in batches held out from the training set, and the results were extraordinary – using deep learning, the winner achieved an average test accuracy of 99.763%! In this talk, I will describe some of the things we have learned about cellular phenotyping with deep learning from both this competition and our own internal research, and outline some of the ways we use such phenotypes for drug discovery and development.           
            	</p>
                <strong>Speaker Bio:</strong>
                <span>Berton Earnshaw is a Machine Learning Fellow at Recursion, where he directs the company’s strategy in applying AI to the company’s multi-petabyte cellular imaging data.  Berton earned a PhD in mathematics from the University of Utah, studying protein trafficking during memory formation, and was a postdoctoral fellow at the University of Utah and Michigan State University, where his research focused on nonautonomous master equations governing receptor kinetics.  Berton then worked in various technical and scientific roles in industry, including CTO of Perfect Pitch, Director of Data Science and Operations at Red Brain Labs, and principal and senior scientist at Savvysherpa (acquired by UnitedHealth Group).
                </span>
            </div>


            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
        	<p>  <strong>Talk Title:</strong>  Applications of AI to Elucidate Mechanisms of Neurodegenerative Disease in Models and Patients</p>
		<strong>Start Time: </strong><span>18:50 PM EDT</span><br>
        	<p> <strong>Speaker:</strong>
		<span>Steve Finkbeiner, M.D., Ph.D., University of California, San Francisco</span></p>
        	<p><center>
		<img class="img-responsive" alt="" src="./img/images/steve.jpg"  width="250" height="300">
		</center></p>
        
       		 <p>
       		<strong> Abstract:</strong> 
         	Neurodegenerative diseases, such as Alzheimer (AD) and Parkinson diseases (PD), are an enormous and growing unmet medical need throughout the world. Unfortunately and despite tremendous efforts, the causes of these disease in the majority of cases remains poorly understood, and the diseases remain incurably fatal. One reason that has been offered to explain the disappointing pace of progress is that these diseases are complex. Most cases are idiopathic, and the field still doesn’t know if clinical syndromes such as AD or PD each have a single cause or multiple causes requiring patient stratification and different therapeutic approaches.
To try to address the complexity of neurodegenerative disease, we have begun to develop and apply new artificial intelligence (AI) tools to data sets that are too big or too complex for humans to fully understand. In this talk, we will illustrate some of the new approaches to our imaging and genomic data to gain new insights from our model systems and patients. For example, we recently showed that we could use deep learning to train neural networks to accurately predict cell structures, cell state and cell function from images of unlabeled cells, something humans are unable to do without labeling. More recently, we have developed a series of AI tools to measure disease-relevant phenotypes from model systems such as patient-derived iPSCs. These include tools that track cells and detect some of the earliest signs of neuronal dysfunction, including changes in neurite morphology and the earliest time points at which neurons commit to undergo degeneration. We have built new robots and developed AI tools to also investigate neurobehavior in high throughput in simple genetic models, such as zebrafish. And recently, we have adapted machine learning tools to glean insights from whole genome sequence and pathology samples from patients with ALS, PD and AD. We are optimistic that new powerful AI-based tools have much to offer investigators trying to uncover the causes of complex neurodegenerative diseases and to eventually find therapies that will be effective.
          	</p>
          
		<strong>Speaker Bio: </strong>
		<span>Dr. Finkbeiner is best known for his pioneering work on brain disorders. He invented robotic microscopy, a new form of imaging that has helped unravel cause-and-effect relationships in amyotrophic lateral sclerosis (ALS, or Lou Gehrig’s disease), Huntington’s, Alzheimer’s, Parkinson’s, autism and schizophrenia. Dr. Finkbeiner used this technology to resolve a long-standing puzzle related to one disease, and a study based with this approach became the most-cited paper in the field of neuroscience of the last decade. The scope and scale of data produced with this approach has enabled the application of deep learning to address some of the critical obstacles to understanding and treating these brain diseases, including disease modeling, early diagnosis, patient stratification, and therapeutic discovery.
 		</span>
-->

        </div>
<br>

    </div>
</body>

</html>