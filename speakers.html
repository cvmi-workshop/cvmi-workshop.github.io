<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Computer Vision for Microscopy Image Analysis 2021</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/speakers.css">
</head>

<body>
    <div class="headBox">
   <!--     <div class="imgBox">
            <img class="logoBox" src="img/images/Picture2.png" alt="">

        </div>  -->

        <div class="navBox">
            <ul>
                <li>
                    <a href="./new.html"><i><strong class="new">New</strong></i></a></li>
                <li>
                    <a href="index.html"><strong>Welcome</strong></a></li>
                <li>
                    <a href="organizers.html"><strong>Organizers</strong></a></li>
                <li>
                    <a href="speakers.html"><strong>Invited Speakers</strong></a></li>
		<li>
                    <a href="program.html"><strong>Program</strong></a></li>
		<li>
                    <a href="registration.html"><strong>Registration</strong></a></li>
                <li>
                    <a href="venue.html"><strong>Attend</strong></a></li>
                <li>
                    <a href="sponsor.html"><strong>Sponsors</strong></a></li>
		<li>
                    <a href="jobs.html"><strong>Jobs</strong></a></li>
		<li>
                    <a href="comittee.html"><strong>Program Committee</strong></a></li>
                <li>
                    <a href="callForPaper.html"><strong>Call for Papers</strong></a></li>
                <li>
                    <a href="dates.html"><strong>Important Dates</strong></a></li>
                <li>
                    <a href="submission.html"><strong>Submission</strong></a></li>
                <li>
                    <a href="accepted.html"><strong>Accepted Papers</strong></a></li>
		<li>
                    <a href="spotlight.html"><strong>Works-in-Progress</strong></a></li>
		<li>
                    <a href="https://motchallenge.net/data/CTMC-v1/" target="_blank"><strong>MOT Challenge</strong></a></li>

                <li>
                    <a href="contact.html"><strong>Contact</strong></a></li>
                <li>
                    <a href="pastcvmi.html"><strong>Past CVMIs</strong></a></li>
            </ul>
        </div>
    </div>

    <div class="contentBox">
        <div class="headImgBox">
            <img class="headImg" src="img/images/Picture20.png" alt="">
        </div>

        <div class="titleBox">
            <p style="font-size: 120%;font-weight: 700;">Invited Speakers</p>
        </div>
        <hr style="height:1px;border:none;border-top:1px solid #555555;">
        <div class="detailBox detailBoxSpeakers">

	  <div>
        <p>  <strong>Talk Title:</strong> Information in images for drug discovery: image-based profiling </p>
  <!--              <strong>Start Time: </strong><span>12:40 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Anne E. Carpenter, Ph.D., Broad Institute of Harvard and MIT. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/Anne.jpg" width="240" height="180">
		</center></p>
		<strong> Abstract:</strong> Cell images contain a vast amount of quantifiable information about the status of the cell: for example, whether it is diseased, whether it is responding to a drug treatment, or whether a pathway has been disrupted by a genetic mutation. We extract hundreds of features of cells from images. Just like transcriptional profiling, the similarities and differences in the patterns of extracted features reveal connections among diseases, drugs, and genes. Improving this pipeline is an active area of research, from feature extraction to batch correction to quality control to assessing similarities.

We are harvesting similarities in image-based profiles to identify, at a single-cell level, how diseases, drugs, and genes affect cells, which can uncover small molecules’ mechanism of action, discover gene functions, predict assay outcomes, discover disease-associated phenotypes, identify the functional impact of disease-associated alleles, and find novel therapeutic candidates. As part of the JUMP-Cell Painting Consortium (Joint Undertaking for Morphological Profiling-Cell Painting) we are aiming to establish experimental and computational best practices for image-based profiling (https://jump-cellpainting.broadinstitute.org/results) and produce the world’s largest public Cell Painting gene/compound image resource, with 140,000 perturbations in five replicates, to be released November 2022. With these data and new technologies like Pooled Cell Painting and variants of the assay like LipocyteProfiler and CardioProfiler, we hope to bring drug discovery-accelerating applications to practice.
		</p>
		<strong>Speaker Bio:</strong>
                <span>Anne Carpenter is senior director of the Imaging Platform at Broad Institute of MIT and Harvard, where she is also an institute scientist. With a strong background in cell biology, microscopy, and computational biology, her expertise is in developing and applying methods for extracting quantitative information from biological images, especially in a high-throughput manner.

Carpenter directs a team of biologists and computer scientists in developing image analysis and data exploration methods and software that are open source and freely available to the public. She and her team developed CellProfiler, the first open-source, high-throughput cell image analysis software. Carpenter is now a pioneer in image-based profiling, the extraction of rich, unbiased information from images for drug discovery, and functional genomics. She collaborates with dozens of biomedical research groups around the world to use image analysis to identify disease states, therapeutic potential, and gene function from microscopy images.

Carpenter is an NIH MIRA investigator, an NSF CAREER awardee, and has received recognition and research funding from numerous other groups including the Human Frontiers in Science program and the Howard Hughes Medical Institute. She was recently named to the top-100 list of AI Leaders in Drug Discovery and Healthcare by Deep Knowledge Analytics, and she is an honorary fellow of the Royal Microscopical Society.

Carpenter earned her B.S. from Purdue University and her Ph.D. from the University of Illinois at Urbana-Champaign.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    
	 <div>
<!--		<p>  <strong>Talk Title:</strong> AI – New Horizons for Histopathology</p>
                <strong>Start Time: </strong><span>13:20 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Kaupo Palo, Ph.D., PerkinElmer. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/kaupo.jpg" width="210" height="220">
		</center></p>
<!-- <strong> Abstract:</strong> Machine learning and image analysis allows to interrogate morphological patterns with a precision and accuracy that exceeds human performance. The talk will highlight recent results that demonstrate the possibility of identifying morphological correlates of molecular subtypes in colorectal cancer using histology alone. Not only will this technology open up new opportunities for cellular pathology, it will also provide new ways for introducing certain molecular tests into the clinical workflow. Combined with new tissue imaging technologies that can visualise multiple different proteins in the same tissue section we can now interrogate tissues with a depth and resolution that has not been possible before.  In addition, I outline efforts for improving the pathology workflows using AI.</p>
		-->
		<strong>Speaker Bio:</strong>
                <span>Kaupo Palo studied physics at Tartu University, Estonia. He received his PhD in theoretical physics in Uppsala University, Sweden in 1994. Kaupo held his position as post-doctoral fellow in CERN, Geneva in 1994-1996. Shortly after he joined Hamburg based biotech company Evotec to contribute to the technologies based on single molecule spectroscopy. While the pharmaceutical industry and research turned more towards cellular microscopy, the company started producing microscopes for high content screening. From 2007 he joined PerkinElmer through acquisition. Kaupo's work became more focused on image processing and image analysis.
He contributed in areas of microscope design such as designing pinhole pattern of Nipkow disks, using Penrose tiling for image registration, designed methods for image processing such as digital phase contrast, shading correction, and designed pipelines for image analysis from segmentation to quantitation. In recent years he has investigated opportunities offered by Deep Learning in areas of image processing, object segmentation and classification.</span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
            <div>
 <!--               <p>  <strong>Talk Title:</strong>  Computer Vision Opportunities for Analyzing the Spatial Topography of Gene Expression in the Human Brain </p>
		<strong>Start Time: </strong><span>14:50 PM EDT</span><br> -->
		<strong>Speaker:</strong>
                <span>Michael Tangrea, Ph.D., Loyola University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/tangrea.jpg" width="220" height="220">
		</center></p>
<!--		<strong> Abstract:</strong> The spatial organization of the brain is fundamentally related to its function. Understanding complex brain disorders will require identifying cell types that make up the brain and ultimately linking functional correlates of individual cell classes with spatial topography. Emerging approaches like spatial transcriptomics (ST) can quantify RNA transcripts within tissue architecture (defined by histological images), thereby retaining both anatomical and transcriptome-scale molecular information. To further our understanding of gene expression within the context of the spatial organization of the human cortex, we used the 10x Genomics Visium platform, a novel barcoding-based transcriptome-wide ST technology that maps RNA-sequencing reads to specific positions on a histological image, to generate spatial maps of gene expression in the six-layered dorsolateral prefrontal cortex (DLPFC) of the adult human brain.: We show that Visium and its combined proteomics platform (Visium-IF) can identify gene expression with high spatial resolution within the architecture of the human cortex. We discuss computer vision opportunities for further integrating Visium gene expression and histology/fluorescence microscopy data for spatial and pathological registration of gene expression in the normal brain as well as the brains of individuals with complex brain disorders.
           	 </p>
		-->
		<strong>Speaker Bio:</strong>
                <span>Dr. Tangrea is an Endowed Professor in the Biology Department at Loyola University Maryland. He also works closely with the Center for Innovation and Entrepreneurship. Dr. Tangrea is a translational researcher who specializes in the development of novel pathology technologies that facilitate improved biomolecular analysis of tissue specimens for translational research, tissue diagnostics and precision medicine.
He is the inventor on multiple patents and author of over 40 scientific publications and
invited speaker to diverse, technical audiences. He is the Co-Founder of BioNavigators (formerly the Mid-Atlantic Biology Research and Career [MABRC] Network) and is a Mentor to Life Science start-ups.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
 
            <div>
		<p>  <strong>Talk Title:</strong> Traditional and Deep Learning Models of Cellular Structure </p>
	<!--	<strong>Start Time: </strong><span>15:30 PM EDT</span><br>  -->
                <strong>Speaker:</strong>
                <span>Robert Murphy Professor,Carnegie Mellon University. </span><strong></strong> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/murphy.jpg" width="200" height="230">
		</center></p>
		<strong> Abstract:</strong> A major challenge in computer vision applications in microscopy is creating accurate models of cell structures. Cells have a higher degree of stochasticity and a larger number of components than most subjects of computer vision applications, even higher than other natural objects like plants and animals, complicating use of both traditional and deep learning methods.  Most cellular components are distinct objects with defined boundaries that do not overlap.  Thus challenges include not only segmentation and scene parsing but also construction of generative models that are object-based.  Our work on this subject using traditional methods introduced the idea of constructing objects whose position within the cell was conditional upon other parts, such as the cell membranes, nuclear membranes and microtubules.  With the advent of deep learning and the creation by the Allen Institute of large 3D image collections in which particular organelles were fluorescently-labeled, a significant advance occurred through the creation of conditional autoencoder models for organelles.  A second advance occurred with using a U-net approach to make these models to all be conditional upon a common reference, unlabeled image, which allowed the relationships between different organelles to be at least partially inferred.  We have developed an alternative GAN-based approach and have evaluated how well both models preserve the expected property that organelles do not overlap.  We then developed a modified loss function that allows retraining of the models to minimize that overlap.  We have also developed approaches using our object-based modeling system to evaluate how well synthetic images capture object shape and spatial distribution.
            	</p>  
		<strong>Speaker Bio:</strong>
                <span>Robert F. Murphy is Professor of Computational Biology Emeritus in the School of Computer Science at Carnegie Mellon University.  He was the Ray and Stephanie Lane Professor of Computational Biology and Professor of Biological Sciences, Biomedical Engineering, and Machine Learning at Carnegie Mellon until his retirement in May 2021.  He founded the Computational Biology Department in the School of Computer Science and served as its head from 2009 to 2020.  He is a Fellow of the IEEE and of the American Institute of Medical and Biological Engineering.
Dr. Murphy’s career has centered on combining cell measurements with quantitative and computational methods. In the mid 1990’s, his group pioneered the application of machine learning methods to high-resolution fluorescence microscope images depicting subcellular location patterns, and was the first to demonstrate superior machine performance in interpreting diverse patterns in biological images compared to human interpretation.  His main areas of focus are computer vision methods for biomedical image analysis and AI systems for autonomously driving closed-loop experimental science campaigns.

                <br>
		</span>
            
	    </div> -->

    	    <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
          <p>  <strong>Talk Title:</strong>  Image-based Cell Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:00 PM EDT</span><br>  -->
		<strong>Speaker:</strong>
                <span>Mu Zhou, Ph.D., Stanford University. </span> <br>
                <p><center>
		<img class="img-responsive" alt="" src="./img/images/muzhou.jpg" width="200" height="220">
		</center></p>
		<p>
  <!--         	<strong> Abstract:</strong> Visual cell phenotyping is the characterization and quantification of observable cellular traits in images. Recently, cellular phenotyping has undergone a massive overhaul in terms of the scale, resolution, and throughput, attributable to the advances across electronic, optical, and chemical technologies for imaging cells. Coupled with the rapid acceleration of deep-learning based computational tools, these advances have opened up new avenues for innovation across a wide variety of high-throughput cell biology applications. In this talk, we will review applications where deep learning is powering the recognition, profiling, and prediction of visual phenotypes to answer important biological questions. As the complexity and scale of imaging assays increase to understand biological models, deep learning offers computational solutions to improve our ability for studying more precise details of cellular phenotypes.
           
            	</p>  -->
		<strong>Speaker Bio:</strong>
                <span>Dr. Mu Zhou is a research scientist at Stanford Center for Biomedical Informatics Research. His research interests span the fields of deep learning, medical image analysis, and clinical informatics. He designs and implements approaches to mine quantitative information from the emerging "Big Health Data". The findings will enable early detection of disease, outcome prediction, and medical decision support. In particular, he works with Olivier Gevaert and Sandy Napel at Department of Radiology, Stanford to develop computational models that integrate clinical imaging, high-throughput 'omic' data, and clinical information, enabling identification of novel biomarkers to improve diagnostic precision and optimize therapy management for cancer patients. He is also investigating pediatric neuro-oncology at Lucile Packard Children's Hospital Stanford.
He earned the Ph.D. degree in Computer Science and Engineering from University of South Florida, 2015, advised by professors Lawrence Hall and Dmitry Goldgof. He has also been advised by Robert Gatenby and Robert Gillies at H.Lee Moffitt Cancer Research Institute, Tampa, Florida, where he led the development of clinical imaging analysis in brain cancer with emphasis on characterizing tumor imaging information for accurate diagnosis, disease subtype classification, and tailed planning of treatment.
                </span>
            </div>

            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
<!--            <div>
                <p>  <strong>Talk Title:</strong>  What We’ve Learned from RxRx1 So Far: Cellular Phenotyping with Deep Learning</p>
                <strong>Start Time: </strong><span>17:40 PM EDT</span><br>
                <p><strong>Speaker:</strong>
                <span>Berton Earnshaw, Ph.D., Recursion Pharmaceuticals </span><strong></strong> </p>
		<p><center>
		<img class="img-responsive" alt="" src="./img/images/Berton.jfif" width="300" height="300">
		</center></p>
           	<strong> Abstract:</strong> In 2019, Recursion released its first public dataset in the RxRx series called RxRx1. It consists of over 125,000 fluorescent microscopy images of siRNA-treated cells from more than 50 different executions of the same experiment design in four cell types. Over 1,100 different siRNA were used in the design, thus RxRx1 contains images of cells under a wide variety of genetic perturbations in a large number of experimental batches. Recursion subsequently hosted a competition on Kaggle challenging competitors to correctly classify these cellular phenotypes in batches held out from the training set, and the results were extraordinary – using deep learning, the winner achieved an average test accuracy of 99.763%! In this talk, I will describe some of the things we have learned about cellular phenotyping with deep learning from both this competition and our own internal research, and outline some of the ways we use such phenotypes for drug discovery and development.           
            	</p>
                <strong>Speaker Bio:</strong>
                <span>Berton Earnshaw is a Machine Learning Fellow at Recursion, where he directs the company’s strategy in applying AI to the company’s multi-petabyte cellular imaging data.  Berton earned a PhD in mathematics from the University of Utah, studying protein trafficking during memory formation, and was a postdoctoral fellow at the University of Utah and Michigan State University, where his research focused on nonautonomous master equations governing receptor kinetics.  Berton then worked in various technical and scientific roles in industry, including CTO of Perfect Pitch, Director of Data Science and Operations at Red Brain Labs, and principal and senior scientist at Savvysherpa (acquired by UnitedHealth Group).
                </span>
            </div>


            <hr style="height:1px;border:none;border-top:1px solid #555555;" />
	    <div>
        	<p>  <strong>Talk Title:</strong>  Applications of AI to Elucidate Mechanisms of Neurodegenerative Disease in Models and Patients</p>
		<strong>Start Time: </strong><span>18:50 PM EDT</span><br>
        	<p> <strong>Speaker:</strong>
		<span>Steve Finkbeiner, M.D., Ph.D., University of California, San Francisco</span></p>
        	<p><center>
		<img class="img-responsive" alt="" src="./img/images/steve.jpg"  width="250" height="300">
		</center></p>
        
       		 <p>
       		<strong> Abstract:</strong> 
         	Neurodegenerative diseases, such as Alzheimer (AD) and Parkinson diseases (PD), are an enormous and growing unmet medical need throughout the world. Unfortunately and despite tremendous efforts, the causes of these disease in the majority of cases remains poorly understood, and the diseases remain incurably fatal. One reason that has been offered to explain the disappointing pace of progress is that these diseases are complex. Most cases are idiopathic, and the field still doesn’t know if clinical syndromes such as AD or PD each have a single cause or multiple causes requiring patient stratification and different therapeutic approaches.
To try to address the complexity of neurodegenerative disease, we have begun to develop and apply new artificial intelligence (AI) tools to data sets that are too big or too complex for humans to fully understand. In this talk, we will illustrate some of the new approaches to our imaging and genomic data to gain new insights from our model systems and patients. For example, we recently showed that we could use deep learning to train neural networks to accurately predict cell structures, cell state and cell function from images of unlabeled cells, something humans are unable to do without labeling. More recently, we have developed a series of AI tools to measure disease-relevant phenotypes from model systems such as patient-derived iPSCs. These include tools that track cells and detect some of the earliest signs of neuronal dysfunction, including changes in neurite morphology and the earliest time points at which neurons commit to undergo degeneration. We have built new robots and developed AI tools to also investigate neurobehavior in high throughput in simple genetic models, such as zebrafish. And recently, we have adapted machine learning tools to glean insights from whole genome sequence and pathology samples from patients with ALS, PD and AD. We are optimistic that new powerful AI-based tools have much to offer investigators trying to uncover the causes of complex neurodegenerative diseases and to eventually find therapies that will be effective.
          	</p>
          
		<strong>Speaker Bio: </strong>
		<span>Dr. Finkbeiner is best known for his pioneering work on brain disorders. He invented robotic microscopy, a new form of imaging that has helped unravel cause-and-effect relationships in amyotrophic lateral sclerosis (ALS, or Lou Gehrig’s disease), Huntington’s, Alzheimer’s, Parkinson’s, autism and schizophrenia. Dr. Finkbeiner used this technology to resolve a long-standing puzzle related to one disease, and a study based with this approach became the most-cited paper in the field of neuroscience of the last decade. The scope and scale of data produced with this approach has enabled the application of deep learning to address some of the critical obstacles to understanding and treating these brain diseases, including disease modeling, early diagnosis, patient stratification, and therapeutic discovery.
 		</span>
-->

        </div>
<br>

    </div>
</body>

</html>